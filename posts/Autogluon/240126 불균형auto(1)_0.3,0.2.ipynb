{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ead89876-ba70-480c-9ed6-8c8863b7c978",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"불균형 데이터 autogluon\"\n",
    "author: \"김보람\"\n",
    "date: \"01/26/2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2183c3b-7e41-4eb8-b640-e46149d6f77b",
   "metadata": {},
   "source": [
    "|구분| throw | split | 비고 |\n",
    "| -- | -- | --  | --   |\n",
    "| 1 | 0.2 | 0.2 | df02 |\n",
    "| 2 | 0.5 | 0.5 | df50 |\n",
    "| 3 | 0.3 | 0.05 |     |\n",
    "| 4 | 0.3 | 0.005 |     |\n",
    "| 5 | 0.3 | 0.0005 |     |\n",
    "| 6 | 0.1 | 0.05 |     |\n",
    "| 7 | 0.1 | 0.005 |     |\n",
    "| 8 | 0.1 | 0.0005 |     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7799dec0-0419-4c9e-a18f-dc7d7ada53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [result1,result2,result3,result4,result5,result6,result7,result8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87f65c04-f2ff-4139-a49c-84f6a7172c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.946741</td>\n",
       "      <td>0.991674</td>\n",
       "      <td>0.968686</td>\n",
       "      <td>0.977246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.906260</td>\n",
       "      <td>0.047538</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.090468</td>\n",
       "      <td>0.919729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.927905</td>\n",
       "      <td>0.394945</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.535906</td>\n",
       "      <td>0.883106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.921079</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.910592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932234</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009732</td>\n",
       "      <td>0.799517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972361</td>\n",
       "      <td>0.729977</td>\n",
       "      <td>0.708889</td>\n",
       "      <td>0.719278</td>\n",
       "      <td>0.847551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986513</td>\n",
       "      <td>0.231579</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.860559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986069</td>\n",
       "      <td>0.228956</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.351421</td>\n",
       "      <td>0.871391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.974359         0.946741      0.991674  0.968686       0.977246\n",
       "0        0.906260         0.047538      0.933333  0.090468       0.919729\n",
       "0        0.927905         0.394945      0.833333  0.535906       0.883106\n",
       "0        0.921079         0.054217      0.900000  0.102273       0.910592\n",
       "0        0.932234         0.004902      0.666667  0.009732       0.799517\n",
       "0        0.972361         0.729977      0.708889  0.719278       0.847551\n",
       "0        0.986513         0.231579      0.733333  0.352000       0.860559\n",
       "0        0.986069         0.228956      0.755556  0.351421       0.871391"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bfdec3-5b07-45b5-9b38-2e8813117310",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4eb91738-6398-4ffc-bbec-fc48fcc8f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "# sklearn\n",
    "from sklearn import model_selection # split함수이용\n",
    "from sklearn import ensemble # RF,GBM\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# gnn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2774d96b-b24a-492b-a587-2815ff6e3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def throw(df, fraud_rate):  # 사기 거래 비율에 맞춰 버려지는 함수!\n",
    "        df1 = df[df['is_fraud'] == 1].copy()\n",
    "        df0 = df[df['is_fraud'] == 0].copy()\n",
    "        df0_downsample = (len(df1) * (1-fraud_rate)) / (len(df0) * fraud_rate)\n",
    "        df0_down = df0.sample(frac=df0_downsample, random_state=42)\n",
    "        df_p = pd.concat([df1, df0_down])\n",
    "        return df_p\n",
    "    \n",
    "    def split_dataframe(data_frame, test_fraud_rate, test_rate=0.3):\n",
    "        n = len(data_frame)\n",
    "    \n",
    "        # 사기 거래와 정상 거래를 분리\n",
    "        fraud_data = data_frame[data_frame['is_fraud'] == 1]\n",
    "        normal_data = data_frame[data_frame['is_fraud'] == 0]\n",
    "\n",
    "        # 테스트 데이터 크기 계산\n",
    "        test_samples = int(test_fraud_rate * (n * test_rate))\n",
    "        remaining_test_samples = int(n * test_rate) - test_samples\n",
    "    \n",
    "        # 사기 거래 및 정상 거래에서 무작위로 테스트 데이터 추출\n",
    "        test_fraud_data = fraud_data.sample(n=test_samples, replace=False)\n",
    "        test_normal_data = normal_data.sample(n=remaining_test_samples, replace=False)\n",
    "\n",
    "        # 테스트 데이터 합치기\n",
    "        test_data = pd.concat([test_normal_data, test_fraud_data])\n",
    "\n",
    "        # 훈련 데이터 생성\n",
    "        train_data = data_frame[~data_frame.index.isin(test_data.index)]\n",
    "\n",
    "        return train_data, test_data\n",
    "    \n",
    "    def concat(df_tr, df_tst):   \n",
    "        df = pd.concat([df_tr, df_tst])\n",
    "        train_mask = np.concatenate((np.full(len(df_tr), True), np.full(len(df_tst), False)))    # index꼬이는거 방지하기 위해서? ★ (이거,, 훔,,?(\n",
    "        test_mask =  np.concatenate((np.full(len(df_tr), False), np.full(len(df_tst), True))) \n",
    "        mask = (train_mask, test_mask)\n",
    "        return df, mask\n",
    "        \n",
    "    def evaluation(y, yhat):\n",
    "        metrics = [sklearn.metrics.accuracy_score,\n",
    "                   sklearn.metrics.precision_score,\n",
    "                   sklearn.metrics.recall_score,\n",
    "                   sklearn.metrics.f1_score,\n",
    "                   sklearn.metrics.roc_auc_score]\n",
    "        return pd.DataFrame({m.__name__:[m(y,yhat).round(6)] for m in metrics})\n",
    "        \n",
    "    def compute_time_difference(group):\n",
    "        n = len(group)\n",
    "        result = []\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                time_difference = abs((group.iloc[i].trans_date_trans_time - group.iloc[j].trans_date_trans_time).total_seconds())\n",
    "                result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n",
    "        return result\n",
    "\n",
    "    def edge_index_save(df, unique_col, theta, gamma):\n",
    "        groups = df.groupby(unique_col)\n",
    "        edge_index = np.array([item for sublist in (compute_time_difference(group) for _, group in groups) for item in sublist])\n",
    "        edge_index = edge_index.astype(np.float64)\n",
    "        filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "        \n",
    "        while os.path.exists(filename):\n",
    "            self.save_attempt += 1\n",
    "            filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "        np.save(filename, edge_index)\n",
    "        #tetha = edge_index_plust_itme[:,].mean()\n",
    "    \n",
    "        \n",
    "        edge_index[:,2] = (np.exp(-edge_index[:,2]/(theta)) != 1)*(np.exp(-edge_index[:,2]/(theta))).tolist()\n",
    "        edge_index = torch.tensor([(int(row[0]), int(row[1])) for row in edge_index if row[2] > gamma], dtype=torch.long).t()\n",
    "        return edge_index\n",
    "    \n",
    "    def edge_index(df, unique_col, theta, gamma):\n",
    "        groups = df.groupby(unique_col)\n",
    "        edge_index = np.array([item for sublist in (compute_time_difference(group) for _, group in groups) for item in sublist])\n",
    "        edge_index = edge_index.astype(np.float64)\n",
    "       # filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "        \n",
    "        # while os.path.exists(filename):\n",
    "        #     self.save_attempt += 1\n",
    "        #     filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "        # np.save(filename, edge_index)\n",
    "        #tetha = edge_index_plust_itme[:,].mean()\n",
    "    \n",
    "        \n",
    "        edge_index[:,2] = (np.exp(-edge_index[:,2]/(theta)) != 1)*(np.exp(-edge_index[:,2]/(theta))).tolist()\n",
    "        edge_index = torch.tensor([(int(row[0]), int(row[1])) for row in edge_index if row[2] > gamma], dtype=torch.long).t()\n",
    "        return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f8b4812-1b25-44e2-bc14-438f74d7e911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2.703190e+15</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>6.304230e+11</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>3.885950e+13</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:00</td>\n",
       "      <td>3.534090e+15</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:00</td>\n",
       "      <td>3.755340e+14</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>2020-03-10 16:07:00</td>\n",
       "      <td>6.011980e+15</td>\n",
       "      <td>fraud_Fadel Inc</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>77.00</td>\n",
       "      <td>Haley</td>\n",
       "      <td>Wagner</td>\n",
       "      <td>F</td>\n",
       "      <td>05561 Farrell Crescent</td>\n",
       "      <td>Annapolis</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0305</td>\n",
       "      <td>-76.5515</td>\n",
       "      <td>92106</td>\n",
       "      <td>Accountant, chartered certified</td>\n",
       "      <td>1943-05-28</td>\n",
       "      <td>45ecd198c65e81e597db22e8d2ef7361</td>\n",
       "      <td>1362931649</td>\n",
       "      <td>38.779464</td>\n",
       "      <td>-76.317042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>2020-03-10 16:07:00</td>\n",
       "      <td>4.839040e+15</td>\n",
       "      <td>fraud_Cremin, Hamill and Reichel</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>116.94</td>\n",
       "      <td>Meredith</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>F</td>\n",
       "      <td>043 Hanson Turnpike</td>\n",
       "      <td>Hedrick</td>\n",
       "      <td>...</td>\n",
       "      <td>41.1826</td>\n",
       "      <td>-92.3097</td>\n",
       "      <td>1583</td>\n",
       "      <td>Geochemist</td>\n",
       "      <td>1999-06-28</td>\n",
       "      <td>c00ce51c6ebb7657474a77b9e0b51f34</td>\n",
       "      <td>1362931670</td>\n",
       "      <td>41.400318</td>\n",
       "      <td>-92.726724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>2020-03-10 16:08:00</td>\n",
       "      <td>5.718440e+11</td>\n",
       "      <td>fraud_O'Connell, Botsford and Hand</td>\n",
       "      <td>home</td>\n",
       "      <td>21.27</td>\n",
       "      <td>Susan</td>\n",
       "      <td>Mills</td>\n",
       "      <td>F</td>\n",
       "      <td>005 Cody Estates</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>...</td>\n",
       "      <td>38.2507</td>\n",
       "      <td>-85.7476</td>\n",
       "      <td>736284</td>\n",
       "      <td>Engineering geologist</td>\n",
       "      <td>1952-04-02</td>\n",
       "      <td>17c9dc8b2a6449ca2473726346e58e6c</td>\n",
       "      <td>1362931711</td>\n",
       "      <td>37.293339</td>\n",
       "      <td>-84.798122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>2020-03-10 16:08:00</td>\n",
       "      <td>4.646850e+18</td>\n",
       "      <td>fraud_Thompson-Gleason</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>9.52</td>\n",
       "      <td>Julia</td>\n",
       "      <td>Bell</td>\n",
       "      <td>F</td>\n",
       "      <td>576 House Crossroad</td>\n",
       "      <td>West Sayville</td>\n",
       "      <td>...</td>\n",
       "      <td>40.7320</td>\n",
       "      <td>-73.1000</td>\n",
       "      <td>4056</td>\n",
       "      <td>Film/video editor</td>\n",
       "      <td>1990-06-25</td>\n",
       "      <td>5ca650881b48a6a38754f841c23b77ab</td>\n",
       "      <td>1362931718</td>\n",
       "      <td>39.773077</td>\n",
       "      <td>-72.213209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>2020-03-10 16:08:00</td>\n",
       "      <td>2.283740e+15</td>\n",
       "      <td>fraud_Buckridge PLC</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>6.81</td>\n",
       "      <td>Shannon</td>\n",
       "      <td>Williams</td>\n",
       "      <td>F</td>\n",
       "      <td>9345 Spencer Junctions Suite 183</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0770</td>\n",
       "      <td>-84.3033</td>\n",
       "      <td>165556</td>\n",
       "      <td>Prison officer</td>\n",
       "      <td>1997-12-27</td>\n",
       "      <td>8d0a575fe635bbde12f1a2bffc126731</td>\n",
       "      <td>1362931730</td>\n",
       "      <td>33.601468</td>\n",
       "      <td>-83.891921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trans_date_trans_time        cc_num  \\\n",
       "0         2019-01-01 00:00:00  2.703190e+15   \n",
       "1         2019-01-01 00:00:00  6.304230e+11   \n",
       "2         2019-01-01 00:00:00  3.885950e+13   \n",
       "3         2019-01-01 00:01:00  3.534090e+15   \n",
       "4         2019-01-01 00:03:00  3.755340e+14   \n",
       "...                       ...           ...   \n",
       "1048570   2020-03-10 16:07:00  6.011980e+15   \n",
       "1048571   2020-03-10 16:07:00  4.839040e+15   \n",
       "1048572   2020-03-10 16:08:00  5.718440e+11   \n",
       "1048573   2020-03-10 16:08:00  4.646850e+18   \n",
       "1048574   2020-03-10 16:08:00  2.283740e+15   \n",
       "\n",
       "                                   merchant        category     amt  \\\n",
       "0                fraud_Rippin, Kub and Mann        misc_net    4.97   \n",
       "1           fraud_Heller, Gutmann and Zieme     grocery_pos  107.23   \n",
       "2                      fraud_Lind-Buckridge   entertainment  220.11   \n",
       "3        fraud_Kutch, Hermiston and Farrell   gas_transport   45.00   \n",
       "4                       fraud_Keeling-Crist        misc_pos   41.96   \n",
       "...                                     ...             ...     ...   \n",
       "1048570                     fraud_Fadel Inc  health_fitness   77.00   \n",
       "1048571    fraud_Cremin, Hamill and Reichel        misc_pos  116.94   \n",
       "1048572  fraud_O'Connell, Botsford and Hand            home   21.27   \n",
       "1048573              fraud_Thompson-Gleason  health_fitness    9.52   \n",
       "1048574                 fraud_Buckridge PLC        misc_pos    6.81   \n",
       "\n",
       "             first      last gender                            street  \\\n",
       "0         Jennifer     Banks      F                    561 Perry Cove   \n",
       "1        Stephanie      Gill      F      43039 Riley Greens Suite 393   \n",
       "2           Edward   Sanchez      M          594 White Dale Suite 530   \n",
       "3           Jeremy     White      M       9443 Cynthia Court Apt. 038   \n",
       "4            Tyler    Garcia      M                  408 Bradley Rest   \n",
       "...            ...       ...    ...                               ...   \n",
       "1048570      Haley    Wagner      F            05561 Farrell Crescent   \n",
       "1048571   Meredith  Campbell      F               043 Hanson Turnpike   \n",
       "1048572      Susan     Mills      F                  005 Cody Estates   \n",
       "1048573      Julia      Bell      F               576 House Crossroad   \n",
       "1048574    Shannon  Williams      F  9345 Spencer Junctions Suite 183   \n",
       "\n",
       "                   city  ...      lat      long  city_pop  \\\n",
       "0        Moravian Falls  ...  36.0788  -81.1781      3495   \n",
       "1                Orient  ...  48.8878 -118.2105       149   \n",
       "2            Malad City  ...  42.1808 -112.2620      4154   \n",
       "3               Boulder  ...  46.2306 -112.1138      1939   \n",
       "4              Doe Hill  ...  38.4207  -79.4629        99   \n",
       "...                 ...  ...      ...       ...       ...   \n",
       "1048570       Annapolis  ...  39.0305  -76.5515     92106   \n",
       "1048571         Hedrick  ...  41.1826  -92.3097      1583   \n",
       "1048572      Louisville  ...  38.2507  -85.7476    736284   \n",
       "1048573   West Sayville  ...  40.7320  -73.1000      4056   \n",
       "1048574      Alpharetta  ...  34.0770  -84.3033    165556   \n",
       "\n",
       "                                       job         dob  \\\n",
       "0                Psychologist, counselling  1988-03-09   \n",
       "1        Special educational needs teacher  1978-06-21   \n",
       "2              Nature conservation officer  1962-01-19   \n",
       "3                          Patent attorney  1967-01-12   \n",
       "4           Dance movement psychotherapist  1986-03-28   \n",
       "...                                    ...         ...   \n",
       "1048570    Accountant, chartered certified  1943-05-28   \n",
       "1048571                         Geochemist  1999-06-28   \n",
       "1048572              Engineering geologist  1952-04-02   \n",
       "1048573                  Film/video editor  1990-06-25   \n",
       "1048574                     Prison officer  1997-12-27   \n",
       "\n",
       "                                trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0        0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1        1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2        a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3        6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4        a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "...                                   ...         ...        ...         ...   \n",
       "1048570  45ecd198c65e81e597db22e8d2ef7361  1362931649  38.779464  -76.317042   \n",
       "1048571  c00ce51c6ebb7657474a77b9e0b51f34  1362931670  41.400318  -92.726724   \n",
       "1048572  17c9dc8b2a6449ca2473726346e58e6c  1362931711  37.293339  -84.798122   \n",
       "1048573  5ca650881b48a6a38754f841c23b77ab  1362931718  39.773077  -72.213209   \n",
       "1048574  8d0a575fe635bbde12f1a2bffc126731  1362931730  33.601468  -83.891921   \n",
       "\n",
       "         is_fraud  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "1048570         0  \n",
       "1048571         0  \n",
       "1048572         0  \n",
       "1048573         0  \n",
       "1048574         0  \n",
       "\n",
       "[1048575 rows x 22 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudTrain = pd.read_csv(\"~/Desktop/fraudTrain.csv\").iloc[:,1:]\n",
    "fraudTrain = fraudTrain.assign(trans_date_trans_time= list(map(lambda x: pd.to_datetime(x), fraudTrain.trans_date_trans_time)))\n",
    "fraudTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed60e7-0257-40eb-ba3a-6f90f6b3342f",
   "metadata": {},
   "source": [
    "# Autogluon(df02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c660f6c2-92c5-4e58-8967-8477870828d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudTrain = fraudTrain[[\"amt\",\"is_fraud\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49bc58b4-948f-42ef-9c3e-d1d2ce72ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto(df,test_fraud_rate):\n",
    "    df_tr, df_tst = split_dataframe(df, test_fraud_rate)\n",
    "    tr = TabularDataset(df_tr)\n",
    "    tst = TabularDataset(df_tst)\n",
    "    predictr = TabularPredictor(\"is_fraud\")\n",
    "    predictr.fit(tr, presets='best_quality')\n",
    "    y = tst.is_fraud\n",
    "    yhat = predictr.predict(tst)\n",
    "    result = evaluation(y,yhat)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfd3c747-4e7e-42fb-9b33-8d526e345213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240126_034006/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240126_034006/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   607.91 GB / 982.82 GB (61.9%)\n",
      "Train Data Rows:    7007\n",
      "Train Data Columns: 21\n",
      "Label Column: is_fraud\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21176.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.95 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['street']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 2\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['trans_num']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['trans_num']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', [])                   : 1 | ['trans_date_trans_time']\n",
      "\t\t('float', [])                      : 6 | ['cc_num', 'amt', 'lat', 'long', 'merch_lat', ...]\n",
      "\t\t('int', [])                        : 3 | ['zip', 'city_pop', 'unix_time']\n",
      "\t\t('object', [])                     : 8 | ['merchant', 'category', 'first', 'last', 'gender', ...]\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['dob']\n",
      "\t\t('object', ['text'])               : 1 | ['street']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  7 | ['merchant', 'category', 'first', 'last', 'city', ...]\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['street']\n",
      "\t\t('float', [])                       :  6 | ['cc_num', 'amt', 'lat', 'long', 'merch_lat', ...]\n",
      "\t\t('int', [])                         :  3 | ['zip', 'city_pop', 'unix_time']\n",
      "\t\t('int', ['binned', 'text_special']) :  8 | ['street.char_count', 'street.word_count', 'street.capital_ratio', 'street.lower_ratio', 'street.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  1 | ['gender']\n",
      "\t\t('int', ['datetime_as_int'])        : 10 | ['trans_date_trans_time', 'trans_date_trans_time.year', 'trans_date_trans_time.month', 'trans_date_trans_time.day', 'trans_date_trans_time.dayofweek', ...]\n",
      "\t\t('int', ['text_ngram'])             :  1 | ['__nlp__.suite']\n",
      "\t1.0s = Fit runtime\n",
      "\t20 features in original data used to generate 37 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.25 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f36a79fe700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f36a79fe700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.8818\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9575\t = Validation score   (accuracy)\n",
      "\t1.72s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9636\t = Validation score   (accuracy)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.9595\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.9593\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9873\t = Validation score   (accuracy)\n",
      "\t10.94s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.9602\t = Validation score   (accuracy)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.9589\t = Validation score   (accuracy)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9235\t = Validation score   (accuracy)\n",
      "\t11.81s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9747\t = Validation score   (accuracy)\n",
      "\t4.35s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8938\t = Validation score   (accuracy)\n",
      "\t31.61s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.959\t = Validation score   (accuracy)\n",
      "\t4.27s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9873\t = Validation score   (accuracy)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 78.9s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240126_034006/\")\n"
     ]
    }
   ],
   "source": [
    "df = throw(fraudTrain, 0.2)\n",
    "tr = TabularDataset(df_tr)\n",
    "tst = TabularDataset(df_tst)\n",
    "predictr = TabularPredictor(\"is_fraud\")\n",
    "predictr.fit(tr, presets='best_quality')\n",
    "y = tst.is_fraud\n",
    "yhat = predictr.predict(tst)\n",
    "result1 = evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446f493-891d-40d9-ab0a-c57772e7e72e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Autogluon(df50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc88b80a-0944-4231-b2a7-ee23847a3560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240126_034125/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240126_034125/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   607.65 GB / 982.82 GB (61.8%)\n",
      "Train Data Rows:    7007\n",
      "Train Data Columns: 21\n",
      "Label Column: is_fraud\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21211.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.95 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['street']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 2\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['trans_num']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['trans_num']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', [])                   : 1 | ['trans_date_trans_time']\n",
      "\t\t('float', [])                      : 6 | ['cc_num', 'amt', 'lat', 'long', 'merch_lat', ...]\n",
      "\t\t('int', [])                        : 3 | ['zip', 'city_pop', 'unix_time']\n",
      "\t\t('object', [])                     : 8 | ['merchant', 'category', 'first', 'last', 'gender', ...]\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['dob']\n",
      "\t\t('object', ['text'])               : 1 | ['street']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  7 | ['merchant', 'category', 'first', 'last', 'city', ...]\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['street']\n",
      "\t\t('float', [])                       :  6 | ['cc_num', 'amt', 'lat', 'long', 'merch_lat', ...]\n",
      "\t\t('int', [])                         :  3 | ['zip', 'city_pop', 'unix_time']\n",
      "\t\t('int', ['binned', 'text_special']) :  8 | ['street.char_count', 'street.word_count', 'street.capital_ratio', 'street.lower_ratio', 'street.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  1 | ['gender']\n",
      "\t\t('int', ['datetime_as_int'])        : 10 | ['trans_date_trans_time', 'trans_date_trans_time.year', 'trans_date_trans_time.month', 'trans_date_trans_time.day', 'trans_date_trans_time.dayofweek', ...]\n",
      "\t\t('int', ['text_ngram'])             :  1 | ['__nlp__.suite']\n",
      "\t0.7s = Fit runtime\n",
      "\t20 features in original data used to generate 37 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.25 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.76s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f368c155f70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f368c155310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.8818\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9575\t = Validation score   (accuracy)\n",
      "\t1.65s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9636\t = Validation score   (accuracy)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.9595\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.9593\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9873\t = Validation score   (accuracy)\n",
      "\t10.84s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.9602\t = Validation score   (accuracy)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.9589\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9235\t = Validation score   (accuracy)\n",
      "\t11.65s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9747\t = Validation score   (accuracy)\n",
      "\t4.41s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8938\t = Validation score   (accuracy)\n",
      "\t30.73s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.959\t = Validation score   (accuracy)\n",
      "\t4.32s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9873\t = Validation score   (accuracy)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 77.6s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240126_034125/\")\n"
     ]
    }
   ],
   "source": [
    "df = throw(fraudTrain, 0.5)\n",
    "tr = TabularDataset(df_tr)\n",
    "tst = TabularDataset(df_tst)\n",
    "predictr = TabularPredictor(\"is_fraud\")\n",
    "predictr.fit(tr, presets='best_quality')\n",
    "y = tst.is_fraud\n",
    "yhat = predictr.predict(tst)\n",
    "result2 = evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760cedae-5b17-4acf-8cb7-9339c74e57fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Autogluon(0.3 / 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "882fa292-f52a-44f7-93e5-a2a2a94f335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240126_050219/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240126_050219/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   606.47 GB / 982.82 GB (61.7%)\n",
      "Train Data Rows:    14014\n",
      "Train Data Columns: 1\n",
      "Label Column: is_fraud\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21246.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\t0.0s = Fit runtime\n",
      "\t1 features in original data used to generate 1 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.8836\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.8731\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8884\t = Validation score   (accuracy)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8961\t = Validation score   (accuracy)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.8669\t = Validation score   (accuracy)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.8669\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8964\t = Validation score   (accuracy)\n",
      "\t1.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.8714\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.8713\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8827\t = Validation score   (accuracy)\n",
      "\t12.2s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8958\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8948\t = Validation score   (accuracy)\n",
      "\t18.45s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8957\t = Validation score   (accuracy)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.897\t = Validation score   (accuracy)\n",
      "\t2.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 48.89s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240126_050219/\")\n"
     ]
    }
   ],
   "source": [
    "df = throw(fraudTrain, 0.3)\n",
    "result3 = auto(df,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16015de8-a5bb-4f77-88fc-d2e92a127fe8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Autogluon(0.3 / 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ded02c0-7679-431e-9071-dfce6b5e9129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240126_051650/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240126_051650/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   604.41 GB / 982.82 GB (61.5%)\n",
      "Train Data Rows:    14014\n",
      "Train Data Columns: 1\n",
      "Label Column: is_fraud\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22354.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\t0.0s = Fit runtime\n",
      "\t1 features in original data used to generate 1 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.8747\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.8688\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8874\t = Validation score   (accuracy)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8931\t = Validation score   (accuracy)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.8576\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.8576\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8923\t = Validation score   (accuracy)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.8639\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.8638\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.879\t = Validation score   (accuracy)\n",
      "\t12.46s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8933\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8901\t = Validation score   (accuracy)\n",
      "\t20.35s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8928\t = Validation score   (accuracy)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8939\t = Validation score   (accuracy)\n",
      "\t2.93s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 51.69s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240126_051650/\")\n"
     ]
    }
   ],
   "source": [
    "df = throw(fraudTrain, 0.3)\n",
    "result4 = auto(df,0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef286ec-f81e-422f-925b-62c13ba37d3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Autogluon(0.3 / 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7ec0e8b-93e0-409b-8450-79fc7dbda741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240126_051742/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240126_051742/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   604.11 GB / 982.82 GB (61.5%)\n",
      "Train Data Rows:    14014\n",
      "Train Data Columns: 1\n",
      "Label Column: is_fraud\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22269.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\t0.0s = Fit runtime\n",
      "\t1 features in original data used to generate 1 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.8746\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.8656\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8898\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.892\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.8588\t = Validation score   (accuracy)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.8588\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8931\t = Validation score   (accuracy)\n",
      "\t1.71s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.8638\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.8643\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.878\t = Validation score   (accuracy)\n",
      "\t12.93s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.893\t = Validation score   (accuracy)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8905\t = Validation score   (accuracy)\n",
      "\t20.83s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8912\t = Validation score   (accuracy)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8935\t = Validation score   (accuracy)\n",
      "\t3.33s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 52.68s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240126_051742/\")\n"
     ]
    }
   ],
   "source": [
    "df = throw(fraudTrain, 0.3)\n",
    "result5 = auto(df,0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba53b9-68b4-47c6-ae5c-930188ed8f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d72b3735-344c-4dd8-963c-2e6386e2d930",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Autogluon(0.1 / 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59e2b570-3894-4799-bd0f-20468fb1b896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240126_051835/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240126_051835/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   603.80 GB / 982.82 GB (61.4%)\n",
      "Train Data Rows:    42042\n",
      "Train Data Columns: 1\n",
      "Label Column: is_fraud\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22269.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.34 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\t0.0s = Fit runtime\n",
      "\t1 features in original data used to generate 1 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.9448\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.9397\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9454\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9527\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.938\t = Validation score   (accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.938\t = Validation score   (accuracy)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9527\t = Validation score   (accuracy)\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.9413\t = Validation score   (accuracy)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.9414\t = Validation score   (accuracy)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9506\t = Validation score   (accuracy)\n",
      "\t37.84s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9528\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9541\t = Validation score   (accuracy)\n",
      "\t70.34s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9527\t = Validation score   (accuracy)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9542\t = Validation score   (accuracy)\n",
      "\t7.95s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 135.79s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240126_051835/\")\n"
     ]
    }
   ],
   "source": [
    "df = throw(fraudTrain, 0.1)\n",
    "result6 = auto(df,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a54308-7c17-49bd-835d-36da9c672ba0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Autogluon(0.1 / 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "837c245a-fadd-47af-ad2d-686b691e09d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240126_052052/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240126_052052/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   603.34 GB / 982.82 GB (61.4%)\n",
      "Train Data Rows:    42042\n",
      "Train Data Columns: 1\n",
      "Label Column: is_fraud\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22163.4 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.34 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\t0.0s = Fit runtime\n",
      "\t1 features in original data used to generate 1 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.9378\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.9318\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9421\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9476\t = Validation score   (accuracy)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.9312\t = Validation score   (accuracy)\n",
      "\t1.2s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.9312\t = Validation score   (accuracy)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.947\t = Validation score   (accuracy)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.9342\t = Validation score   (accuracy)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.9341\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9453\t = Validation score   (accuracy)\n",
      "\t38.15s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9467\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9477\t = Validation score   (accuracy)\n",
      "\t65.84s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9476\t = Validation score   (accuracy)\n",
      "\t0.93s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9485\t = Validation score   (accuracy)\n",
      "\t7.95s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 131.81s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240126_052052/\")\n"
     ]
    }
   ],
   "source": [
    "df = throw(fraudTrain, 0.1)\n",
    "result7 = auto(df,0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718ce1e-2be8-44f6-abff-288799029c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c5af08b-b034-4e25-8bc3-b7bdfe212bfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Autogluon(0.1 / 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21d0f7a2-88d0-48ed-8dfe-76a57a54ea9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240126_052304/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240126_052304/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   602.85 GB / 982.82 GB (61.3%)\n",
      "Train Data Rows:    42042\n",
      "Train Data Columns: 1\n",
      "Label Column: is_fraud\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22155.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.34 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['amt']\n",
      "\t0.0s = Fit runtime\n",
      "\t1 features in original data used to generate 1 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.34 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.937\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.9317\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9419\t = Validation score   (accuracy)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9469\t = Validation score   (accuracy)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.9308\t = Validation score   (accuracy)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.9308\t = Validation score   (accuracy)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9465\t = Validation score   (accuracy)\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.9341\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.9341\t = Validation score   (accuracy)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9451\t = Validation score   (accuracy)\n",
      "\t39.1s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9462\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.948\t = Validation score   (accuracy)\n",
      "\t71.08s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9469\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9481\t = Validation score   (accuracy)\n",
      "\t7.99s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.21s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240126_052304/\")\n"
     ]
    }
   ],
   "source": [
    "df = throw(fraudTrain, 0.1)\n",
    "result8 = auto(df,0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c88fe-2f8b-4da8-a6cb-7c3f3dc11797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
