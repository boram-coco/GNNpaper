{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c8593b37-a6e6-4ccb-b9b2-349f55cb2b69",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"autogluon(tripartite)\"\n",
    "author: \"김보람\"\n",
    "date: \"01/27/2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03341d-db6a-473a-91fa-7d878f69f879",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a397e5a9-c47a-4db7-b73f-bc9a2d965f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
    "\n",
    "# sklearn\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167a4fe6-4f40-4536-b4b5-1b000d7e5f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3417592/1991497680.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df[df[\"is_fraud\"]==0].sample(frac=0.20, random_state=42).append(df[df[\"is_fraud\"] == 1])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>669418</th>\n",
       "      <td>669418</td>\n",
       "      <td>2019-10-12 18:21</td>\n",
       "      <td>4.089100e+18</td>\n",
       "      <td>fraud_Haley, Jewess and Bechtelar</td>\n",
       "      <td>shopping_pos</td>\n",
       "      <td>7.53</td>\n",
       "      <td>Debra</td>\n",
       "      <td>Stark</td>\n",
       "      <td>F</td>\n",
       "      <td>686 Linda Rest</td>\n",
       "      <td>...</td>\n",
       "      <td>32.3836</td>\n",
       "      <td>-94.8653</td>\n",
       "      <td>24536</td>\n",
       "      <td>Multimedia programmer</td>\n",
       "      <td>1983-10-14</td>\n",
       "      <td>d313353fa30233e5fab5468e852d22fc</td>\n",
       "      <td>1350066071</td>\n",
       "      <td>32.202008</td>\n",
       "      <td>-94.371865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32567</th>\n",
       "      <td>32567</td>\n",
       "      <td>2019-01-20 13:06</td>\n",
       "      <td>4.247920e+12</td>\n",
       "      <td>fraud_Turner LLC</td>\n",
       "      <td>travel</td>\n",
       "      <td>3.79</td>\n",
       "      <td>Judith</td>\n",
       "      <td>Moss</td>\n",
       "      <td>F</td>\n",
       "      <td>46297 Benjamin Plains Suite 703</td>\n",
       "      <td>...</td>\n",
       "      <td>39.5370</td>\n",
       "      <td>-83.4550</td>\n",
       "      <td>22305</td>\n",
       "      <td>Television floor manager</td>\n",
       "      <td>1939-03-09</td>\n",
       "      <td>88c65b4e1585934d578511e627fe3589</td>\n",
       "      <td>1327064760</td>\n",
       "      <td>39.156673</td>\n",
       "      <td>-82.930503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156587</th>\n",
       "      <td>156587</td>\n",
       "      <td>2019-03-24 18:09</td>\n",
       "      <td>4.026220e+12</td>\n",
       "      <td>fraud_Klein Group</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>59.07</td>\n",
       "      <td>Debbie</td>\n",
       "      <td>Payne</td>\n",
       "      <td>F</td>\n",
       "      <td>204 Ashley Neck Apt. 169</td>\n",
       "      <td>...</td>\n",
       "      <td>41.5224</td>\n",
       "      <td>-71.9934</td>\n",
       "      <td>4720</td>\n",
       "      <td>Broadcast presenter</td>\n",
       "      <td>1977-05-18</td>\n",
       "      <td>3bd9ede04b5c093143d5e5292940b670</td>\n",
       "      <td>1332612553</td>\n",
       "      <td>41.657152</td>\n",
       "      <td>-72.595751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020243</th>\n",
       "      <td>1020243</td>\n",
       "      <td>2020-02-25 15:12</td>\n",
       "      <td>4.957920e+12</td>\n",
       "      <td>fraud_Monahan-Morar</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>25.58</td>\n",
       "      <td>Alan</td>\n",
       "      <td>Parsons</td>\n",
       "      <td>M</td>\n",
       "      <td>0547 Russell Ford Suite 574</td>\n",
       "      <td>...</td>\n",
       "      <td>39.6171</td>\n",
       "      <td>-102.4776</td>\n",
       "      <td>207</td>\n",
       "      <td>Network engineer</td>\n",
       "      <td>1955-12-04</td>\n",
       "      <td>19e16ee7a01d229e750359098365e321</td>\n",
       "      <td>1361805120</td>\n",
       "      <td>39.080346</td>\n",
       "      <td>-103.213452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116272</th>\n",
       "      <td>116272</td>\n",
       "      <td>2019-03-06 23:19</td>\n",
       "      <td>4.178100e+15</td>\n",
       "      <td>fraud_Kozey-Kuhlman</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>84.96</td>\n",
       "      <td>Jill</td>\n",
       "      <td>Flores</td>\n",
       "      <td>F</td>\n",
       "      <td>639 Cruz Islands</td>\n",
       "      <td>...</td>\n",
       "      <td>41.9488</td>\n",
       "      <td>-86.4913</td>\n",
       "      <td>3104</td>\n",
       "      <td>Horticulturist, commercial</td>\n",
       "      <td>1981-03-29</td>\n",
       "      <td>a0c8641ca1f5d6e243ed5a2246e66176</td>\n",
       "      <td>1331075954</td>\n",
       "      <td>42.502065</td>\n",
       "      <td>-86.732664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0 trans_date_trans_time        cc_num  \\\n",
       "669418       669418      2019-10-12 18:21  4.089100e+18   \n",
       "32567         32567      2019-01-20 13:06  4.247920e+12   \n",
       "156587       156587      2019-03-24 18:09  4.026220e+12   \n",
       "1020243     1020243      2020-02-25 15:12  4.957920e+12   \n",
       "116272       116272      2019-03-06 23:19  4.178100e+15   \n",
       "\n",
       "                                  merchant       category    amt   first  \\\n",
       "669418   fraud_Haley, Jewess and Bechtelar   shopping_pos   7.53   Debra   \n",
       "32567                     fraud_Turner LLC         travel   3.79  Judith   \n",
       "156587                   fraud_Klein Group  entertainment  59.07  Debbie   \n",
       "1020243                fraud_Monahan-Morar  personal_care  25.58    Alan   \n",
       "116272                 fraud_Kozey-Kuhlman  personal_care  84.96    Jill   \n",
       "\n",
       "            last gender                           street  ...      lat  \\\n",
       "669418     Stark      F                   686 Linda Rest  ...  32.3836   \n",
       "32567       Moss      F  46297 Benjamin Plains Suite 703  ...  39.5370   \n",
       "156587     Payne      F         204 Ashley Neck Apt. 169  ...  41.5224   \n",
       "1020243  Parsons      M      0547 Russell Ford Suite 574  ...  39.6171   \n",
       "116272    Flores      F                 639 Cruz Islands  ...  41.9488   \n",
       "\n",
       "             long  city_pop                         job         dob  \\\n",
       "669418   -94.8653     24536       Multimedia programmer  1983-10-14   \n",
       "32567    -83.4550     22305    Television floor manager  1939-03-09   \n",
       "156587   -71.9934      4720         Broadcast presenter  1977-05-18   \n",
       "1020243 -102.4776       207            Network engineer  1955-12-04   \n",
       "116272   -86.4913      3104  Horticulturist, commercial  1981-03-29   \n",
       "\n",
       "                                trans_num   unix_time  merch_lat  merch_long  \\\n",
       "669418   d313353fa30233e5fab5468e852d22fc  1350066071  32.202008  -94.371865   \n",
       "32567    88c65b4e1585934d578511e627fe3589  1327064760  39.156673  -82.930503   \n",
       "156587   3bd9ede04b5c093143d5e5292940b670  1332612553  41.657152  -72.595751   \n",
       "1020243  19e16ee7a01d229e750359098365e321  1361805120  39.080346 -103.213452   \n",
       "116272   a0c8641ca1f5d6e243ed5a2246e66176  1331075954  42.502065  -86.732664   \n",
       "\n",
       "         is_fraud  \n",
       "669418          0  \n",
       "32567           0  \n",
       "156587          0  \n",
       "1020243         0  \n",
       "116272          0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"~/Desktop/fraudTrain.csv\")\n",
    "df = df[df[\"is_fraud\"]==0].sample(frac=0.20, random_state=42).append(df[df[\"is_fraud\"] == 1])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79fa7313-0d35-4090-8294-28f71c7c69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def throw(df, fraud_rate):  # 사기 거래 비율에 맞춰 버려지는 함수!\n",
    "#         df1 = df[df['is_fraud'] == 1].copy()\n",
    "#         df0 = df[df['is_fraud'] == 0].copy()\n",
    "#         df0_downsample = (len(df1) * (1-fraud_rate)) / (len(df0) * fraud_rate)\n",
    "#         df0_down = df0.sample(frac=df0_downsample, random_state=42)\n",
    "#         df_p = pd.concat([df1, df0_down])\n",
    "#         return df_p\n",
    "    \n",
    "#     def split_dataframe(data_frame, test_fraud_rate, test_rate=0.3):\n",
    "#         n = len(data_frame)\n",
    "    \n",
    "#         # 사기 거래와 정상 거래를 분리\n",
    "#         fraud_data = data_frame[data_frame['is_fraud'] == 1]\n",
    "#         normal_data = data_frame[data_frame['is_fraud'] == 0]\n",
    "\n",
    "#         # 테스트 데이터 크기 계산\n",
    "#         test_samples = int(test_fraud_rate * (n * test_rate))\n",
    "#         remaining_test_samples = int(n * test_rate) - test_samples\n",
    "    \n",
    "#         # 사기 거래 및 정상 거래에서 무작위로 테스트 데이터 추출\n",
    "#         test_fraud_data = fraud_data.sample(n=test_samples, replace=False)\n",
    "#         test_normal_data = normal_data.sample(n=remaining_test_samples, replace=False)\n",
    "\n",
    "#         # 테스트 데이터 합치기\n",
    "#         test_data = pd.concat([test_normal_data, test_fraud_data])\n",
    "\n",
    "#         # 훈련 데이터 생성\n",
    "#         train_data = data_frame[~data_frame.index.isin(test_data.index)]\n",
    "\n",
    "#         return train_data, test_data\n",
    "    \n",
    "#     def concat(df_tr, df_tst):   \n",
    "#         df = pd.concat([df_tr, df_tst])\n",
    "#         train_mask = np.concatenate((np.full(len(df_tr), True), np.full(len(df_tst), False)))    # index꼬이는거 방지하기 위해서? ★ (이거,, 훔,,?(\n",
    "#         test_mask =  np.concatenate((np.full(len(df_tr), False), np.full(len(df_tst), True))) \n",
    "#         mask = (train_mask, test_mask)\n",
    "#         return df, mask\n",
    "        \n",
    "def evaluation(y, yhat):\n",
    "    metrics = [sklearn.metrics.accuracy_score,\n",
    "               sklearn.metrics.precision_score,\n",
    "               sklearn.metrics.recall_score,\n",
    "               sklearn.metrics.f1_score,\n",
    "               sklearn.metrics.roc_auc_score]\n",
    "    return pd.DataFrame({m.__name__:[m(y,yhat).round(6)] for m in metrics})\n",
    "        \n",
    "#     def compute_time_difference(group):\n",
    "#         n = len(group)\n",
    "#         result = []\n",
    "#         for i in range(n):\n",
    "#             for j in range(n):\n",
    "#                 time_difference = abs((group.iloc[i].trans_date_trans_time - group.iloc[j].trans_date_trans_time).total_seconds())\n",
    "#                 result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n",
    "#         return result\n",
    "\n",
    "#     def edge_index_save(df, unique_col, theta, gamma):\n",
    "#         groups = df.groupby(unique_col)\n",
    "#         edge_index = np.array([item for sublist in (compute_time_difference(group) for _, group in groups) for item in sublist])\n",
    "#         edge_index = edge_index.astype(np.float64)\n",
    "#         filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "        \n",
    "#         while os.path.exists(filename):\n",
    "#             self.save_attempt += 1\n",
    "#             filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "#         np.save(filename, edge_index)\n",
    "#         #tetha = edge_index_plust_itme[:,].mean()\n",
    "    \n",
    "        \n",
    "#         edge_index[:,2] = (np.exp(-edge_index[:,2]/(theta)) != 1)*(np.exp(-edge_index[:,2]/(theta))).tolist()\n",
    "#         edge_index = torch.tensor([(int(row[0]), int(row[1])) for row in edge_index if row[2] > gamma], dtype=torch.long).t()\n",
    "#         return edge_index\n",
    "    \n",
    "#     def edge_index(df, unique_col, theta, gamma):\n",
    "#         groups = df.groupby(unique_col)\n",
    "#         edge_index = np.array([item for sublist in (compute_time_difference(group) for _, group in groups) for item in sublist])\n",
    "#         edge_index = edge_index.astype(np.float64)\n",
    "#        # filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "        \n",
    "#         # while os.path.exists(filename):\n",
    "#         #     self.save_attempt += 1\n",
    "#         #     filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "#         # np.save(filename, edge_index)\n",
    "#         #tetha = edge_index_plust_itme[:,].mean()\n",
    "    \n",
    "        \n",
    "#         edge_index[:,2] = (np.exp(-edge_index[:,2]/(theta)) != 1)*(np.exp(-edge_index[:,2]/(theta))).tolist()\n",
    "#         edge_index = torch.tensor([(int(row[0]), int(row[1])) for row in edge_index if row[2] > gamma], dtype=torch.long).t()\n",
    "#         return edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5f718-5b3e-4c30-8d67-f30a737143bb",
   "metadata": {},
   "source": [
    "# 삼분그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4f50b6-213c-4b04-b3bd-4ff0a8221ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_tripartite(df_input, graph_type=nx.Graph()):\n",
    "    df=df_input.copy()\n",
    "    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n",
    "                                                       df[\"cc_num\"].values.tolist() +\n",
    "                                                       df[\"merchant\"].values.tolist()))}\n",
    "    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n",
    "    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n",
    "    \n",
    "        \n",
    "    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n",
    "                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")\n",
    "     \n",
    "    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n",
    "    \n",
    "    \n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d2633-61e6-4a0e-aee5-5d676f3bf563",
   "metadata": {},
   "source": [
    "# 지도학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5009e55c-ddce-4e97-88be-4f51f5024fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6006\n",
      "0    6006\n",
      "Name: is_fraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df.is_fraud==0]\n",
    "df_minority = df[df.is_fraud==1]\n",
    "\n",
    "df_maj_dowsampled = resample(df_majority,\n",
    "                             n_samples=len(df_minority),\n",
    "                             random_state=42)\n",
    "\n",
    "df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n",
    "\n",
    "print(df_downsampled.is_fraud.value_counts())\n",
    "G_down = build_graph_tripartite(df_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4d688a-3112-40c9-9f78-afb58275427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n",
    "                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n",
    "                                                                      test_size=0.20, \n",
    "                                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfe29674-c331-4333-94e4-ae4b9bfcb532",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs = list(G_down.edges)\n",
    "train_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()\n",
    "train_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6062b793-e4ec-4cb9-ab77-2a5c05af9456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e4854e31794d16988cbfd8124218da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/13541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:25<00:00,  2.55s/it]\n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "339fb7a7-2a55-4d59-aebb-9a0b16dd98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [HadamardEmbedder]#, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "# DataFrame 합치기\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "\n",
    "\n",
    "label = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31f5de58-ffc2-4fbd-9156-a4f5239c7fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240127_073147/\"\n"
     ]
    }
   ],
   "source": [
    "predictr = TabularPredictor(label='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c9f9397-2c08-4446-b6fe-f9a5a2c390de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240127_073147/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   600.47 GB / 982.82 GB (61.1%)\n",
      "Train Data Rows:    19067\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18703.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.76 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.76 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 17160, Val Rows: 1907\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1f5074790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.7677\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1822f20d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.7666\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.24279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7635\t = Validation score   (accuracy)\n",
      "\t2.77s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.7368\t = Validation score   (accuracy)\n",
      "\t2.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7467\t = Validation score   (accuracy)\n",
      "\t4.3s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7488\t = Validation score   (accuracy)\n",
      "\t6.1s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7556\t = Validation score   (accuracy)\n",
      "\t9.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.763\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7609\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7892\t = Validation score   (accuracy)\n",
      "\t11.87s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7593\t = Validation score   (accuracy)\n",
      "\t10.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7383\t = Validation score   (accuracy)\n",
      "\t16.03s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7646\t = Validation score   (accuracy)\n",
      "\t11.8s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8076\t = Validation score   (accuracy)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 79.69s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240127_073147/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7fa1ed618dc0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.fit(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9c57b1d-2873-4023-af50-ca79b45e1588",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6821332b-290c-4f26-bedd-7c7c3e98e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "499be333-f1bb-4375-9ba0-188341d1337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1f5061820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1b7d08e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "y = np.array(test_labels)\n",
    "\n",
    "yhat = predictr.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1655077c-e84b-46f0-8674-73681c93d416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.498427</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.501651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.498427              0.7      0.005836  0.011575       0.501651"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ac78e-59fa-4ea3-b9d0-6ca7d1021823",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fcc9f6b-cc6b-4056-b382-08afe22e5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [HadamardEmbedder]#, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "# DataFrame 합치기\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "\n",
    "\n",
    "label = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "814f5ff4-5d0b-4655-8701-015e45982b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240127_073147/\"\n"
     ]
    }
   ],
   "source": [
    "predictr = TabularPredictor(label='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fea35e0-6995-45df-b168-3c8a1432501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240127_073147/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   600.47 GB / 982.82 GB (61.1%)\n",
      "Train Data Rows:    19067\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18703.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.76 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.76 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 17160, Val Rows: 1907\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1f5074790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.7677\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1822f20d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.7666\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.24279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7635\t = Validation score   (accuracy)\n",
      "\t2.77s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.7368\t = Validation score   (accuracy)\n",
      "\t2.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7467\t = Validation score   (accuracy)\n",
      "\t4.3s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7488\t = Validation score   (accuracy)\n",
      "\t6.1s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7556\t = Validation score   (accuracy)\n",
      "\t9.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.763\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7609\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7892\t = Validation score   (accuracy)\n",
      "\t11.87s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7593\t = Validation score   (accuracy)\n",
      "\t10.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7383\t = Validation score   (accuracy)\n",
      "\t16.03s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7646\t = Validation score   (accuracy)\n",
      "\t11.8s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8076\t = Validation score   (accuracy)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 79.69s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240127_073147/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7fa1ed618dc0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.fit(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e057225-fa79-4029-acac-71555a36364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b431939-8da5-48d8-81a4-6615731ae901",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffe44e80-f45a-4b3e-a424-63750d8816da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1f5061820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1b7d08e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "y = np.array(test_labels)\n",
    "\n",
    "yhat = predictr.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc3f80d1-6920-483f-b799-fadd7a2f114f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.498427</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.501651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.498427              0.7      0.005836  0.011575       0.501651"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d7680-d3a4-4aa6-80af-4b4fb1f42443",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fbe11c2-48d5-402c-902d-230591d21f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240127_073500/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240127_073500/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   599.89 GB / 982.82 GB (61.0%)\n",
      "Train Data Rows:    19067\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18646.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.76 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.76 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 17160, Val Rows: 1907\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1f5108af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.7252\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1f5108af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.7257\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.227583\n",
      "[2000]\tvalid_set's binary_error: 0.214997\n",
      "[3000]\tvalid_set's binary_error: 0.209229\n",
      "[4000]\tvalid_set's binary_error: 0.203461\n",
      "[5000]\tvalid_set's binary_error: 0.201888\n",
      "[6000]\tvalid_set's binary_error: 0.203985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7997\t = Validation score   (accuracy)\n",
      "\t13.14s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.226534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7829\t = Validation score   (accuracy)\n",
      "\t4.43s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7425\t = Validation score   (accuracy)\n",
      "\t3.34s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7488\t = Validation score   (accuracy)\n",
      "\t4.8s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7944\t = Validation score   (accuracy)\n",
      "\t65.85s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7493\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7472\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.8464\t = Validation score   (accuracy)\n",
      "\t9.77s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7908\t = Validation score   (accuracy)\n",
      "\t7.2s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8311\t = Validation score   (accuracy)\n",
      "\t19.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7834\t = Validation score   (accuracy)\n",
      "\t8.34s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8542\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 141.06s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240127_073500/\")\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1f5074820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1f5074790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.591777</td>\n",
       "      <td>0.82311</td>\n",
       "      <td>0.240517</td>\n",
       "      <td>0.372258</td>\n",
       "      <td>0.594076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.591777          0.82311      0.240517  0.372258       0.594076"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [AverageEmbedder] # , HadamardEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "# DataFrame 합치기\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "\n",
    "\n",
    "label = np.array(train_labels)\n",
    "\n",
    "predictr = TabularPredictor(label='label')\n",
    "\n",
    "predictr.fit(df) \n",
    "\n",
    "test = np.array(test_embeddings)\n",
    "\n",
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)\n",
    "\n",
    "y = np.array(test_labels)\n",
    "\n",
    "yhat = predictr.predict(test_df)\n",
    "\n",
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02e17839-28f0-4450-b98f-87183b63b626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240127_073726/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240127_073726/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   599.32 GB / 982.82 GB (61.0%)\n",
      "Train Data Rows:    19067\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18658.69 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.76 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.76 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 17160, Val Rows: 1907\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1b7d08dc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5501\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1b7d08dc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5506\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.646\t = Validation score   (accuracy)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6403\t = Validation score   (accuracy)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.635\t = Validation score   (accuracy)\n",
      "\t3.6s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6392\t = Validation score   (accuracy)\n",
      "\t5.08s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.656\t = Validation score   (accuracy)\n",
      "\t4.77s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6329\t = Validation score   (accuracy)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6382\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 3: early stopping\n",
      "\t0.6361\t = Validation score   (accuracy)\n",
      "\t9.47s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6319\t = Validation score   (accuracy)\n",
      "\t2.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6518\t = Validation score   (accuracy)\n",
      "\t5.81s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6408\t = Validation score   (accuracy)\n",
      "\t3.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6686\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 40.83s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240127_073726/\")\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1822f2790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fa1f5074790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.496119              0.0           0.0       0.0       0.499367"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [WeightedL1Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "# DataFrame 합치기\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "\n",
    "\n",
    "label = np.array(train_labels)\n",
    "\n",
    "predictr = TabularPredictor(label='label')\n",
    "\n",
    "predictr.fit(df) \n",
    "\n",
    "test = np.array(test_embeddings)\n",
    "\n",
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)\n",
    "\n",
    "y = np.array(test_labels)\n",
    "\n",
    "yhat = predictr.predict(test_df)\n",
    "\n",
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d96706-6fd7-45e1-ae49-7513f28694e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
