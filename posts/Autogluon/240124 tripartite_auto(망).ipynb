{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c8593b37-a6e6-4ccb-b9b2-349f55cb2b69",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"[Autogluon] (tripartite)_f1값이 너무 안 나오는데..(망함)\"\n",
    "author: \"김보람\"\n",
    "date: \"01/24/2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03341d-db6a-473a-91fa-7d878f69f879",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a397e5a9-c47a-4db7-b73f-bc9a2d965f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
    "\n",
    "# sklearn\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79fa7313-0d35-4090-8294-28f71c7c69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def throw(df, fraud_rate):  # 사기 거래 비율에 맞춰 버려지는 함수!\n",
    "        df1 = df[df['is_fraud'] == 1].copy()\n",
    "        df0 = df[df['is_fraud'] == 0].copy()\n",
    "        df0_downsample = (len(df1) * (1-fraud_rate)) / (len(df0) * fraud_rate)\n",
    "        df0_down = df0.sample(frac=df0_downsample, random_state=42)\n",
    "        df_p = pd.concat([df1, df0_down])\n",
    "        return df_p\n",
    "    \n",
    "    def split_dataframe(data_frame, test_fraud_rate, test_rate=0.3):\n",
    "        n = len(data_frame)\n",
    "    \n",
    "        # 사기 거래와 정상 거래를 분리\n",
    "        fraud_data = data_frame[data_frame['is_fraud'] == 1]\n",
    "        normal_data = data_frame[data_frame['is_fraud'] == 0]\n",
    "\n",
    "        # 테스트 데이터 크기 계산\n",
    "        test_samples = int(test_fraud_rate * (n * test_rate))\n",
    "        remaining_test_samples = int(n * test_rate) - test_samples\n",
    "    \n",
    "        # 사기 거래 및 정상 거래에서 무작위로 테스트 데이터 추출\n",
    "        test_fraud_data = fraud_data.sample(n=test_samples, replace=False)\n",
    "        test_normal_data = normal_data.sample(n=remaining_test_samples, replace=False)\n",
    "\n",
    "        # 테스트 데이터 합치기\n",
    "        test_data = pd.concat([test_normal_data, test_fraud_data])\n",
    "\n",
    "        # 훈련 데이터 생성\n",
    "        train_data = data_frame[~data_frame.index.isin(test_data.index)]\n",
    "\n",
    "        return train_data, test_data\n",
    "    \n",
    "    def concat(df_tr, df_tst):   \n",
    "        df = pd.concat([df_tr, df_tst])\n",
    "        train_mask = np.concatenate((np.full(len(df_tr), True), np.full(len(df_tst), False)))    # index꼬이는거 방지하기 위해서? ★ (이거,, 훔,,?(\n",
    "        test_mask =  np.concatenate((np.full(len(df_tr), False), np.full(len(df_tst), True))) \n",
    "        mask = (train_mask, test_mask)\n",
    "        return df, mask\n",
    "        \n",
    "    def evaluation(y, yhat):\n",
    "        metrics = [sklearn.metrics.accuracy_score,\n",
    "                   sklearn.metrics.precision_score,\n",
    "                   sklearn.metrics.recall_score,\n",
    "                   sklearn.metrics.f1_score,\n",
    "                   sklearn.metrics.roc_auc_score]\n",
    "        return pd.DataFrame({m.__name__:[m(y,yhat).round(6)] for m in metrics})\n",
    "        \n",
    "    def compute_time_difference(group):\n",
    "        n = len(group)\n",
    "        result = []\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                time_difference = abs((group.iloc[i].trans_date_trans_time - group.iloc[j].trans_date_trans_time).total_seconds())\n",
    "                result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n",
    "        return result\n",
    "\n",
    "    def edge_index_save(df, unique_col, theta, gamma):\n",
    "        groups = df.groupby(unique_col)\n",
    "        edge_index = np.array([item for sublist in (compute_time_difference(group) for _, group in groups) for item in sublist])\n",
    "        edge_index = edge_index.astype(np.float64)\n",
    "        filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "        \n",
    "        while os.path.exists(filename):\n",
    "            self.save_attempt += 1\n",
    "            filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "        np.save(filename, edge_index)\n",
    "        #tetha = edge_index_plust_itme[:,].mean()\n",
    "    \n",
    "        \n",
    "        edge_index[:,2] = (np.exp(-edge_index[:,2]/(theta)) != 1)*(np.exp(-edge_index[:,2]/(theta))).tolist()\n",
    "        edge_index = torch.tensor([(int(row[0]), int(row[1])) for row in edge_index if row[2] > gamma], dtype=torch.long).t()\n",
    "        return edge_index\n",
    "    \n",
    "    def edge_index(df, unique_col, theta, gamma):\n",
    "        groups = df.groupby(unique_col)\n",
    "        edge_index = np.array([item for sublist in (compute_time_difference(group) for _, group in groups) for item in sublist])\n",
    "        edge_index = edge_index.astype(np.float64)\n",
    "       # filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "        \n",
    "        # while os.path.exists(filename):\n",
    "        #     self.save_attempt += 1\n",
    "        #     filename = f\"edge_index_attempt{self.save_attempt}_{str(unique_col).replace(' ', '').replace('_', '')}.npy\"\n",
    "        # np.save(filename, edge_index)\n",
    "        #tetha = edge_index_plust_itme[:,].mean()\n",
    "    \n",
    "        \n",
    "        edge_index[:,2] = (np.exp(-edge_index[:,2]/(theta)) != 1)*(np.exp(-edge_index[:,2]/(theta))).tolist()\n",
    "        edge_index = torch.tensor([(int(row[0]), int(row[1])) for row in edge_index if row[2] > gamma], dtype=torch.long).t()\n",
    "        return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b16bdd74-66b8-483c-bfd8-61d55b3ac6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Desktop/fraudTrain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5f718-5b3e-4c30-8d67-f30a737143bb",
   "metadata": {},
   "source": [
    "# 삼분그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4f50b6-213c-4b04-b3bd-4ff0a8221ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_tripartite(df_input, graph_type=nx.Graph()):\n",
    "    df=df_input.copy()\n",
    "    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n",
    "                                                       df[\"cc_num\"].values.tolist() +\n",
    "                                                       df[\"merchant\"].values.tolist()))}\n",
    "    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n",
    "    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n",
    "    \n",
    "        \n",
    "    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n",
    "                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")\n",
    "     \n",
    "    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n",
    "    \n",
    "    \n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330c9b0-e28b-457c-bdb8-5fd1e9473d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d59d2633-61e6-4a0e-aee5-5d676f3bf563",
   "metadata": {},
   "source": [
    "# 지도학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96047969-4075-45cf-8dc4-174f1bff1ab7",
   "metadata": {},
   "source": [
    "### 0.3 / 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50589c00-7157-4625-a0b5-413e8a243ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = throw(df, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbe9a04-b419-4c8c-b7e5-e21e56d3b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr, df_tst = split_dataframe(df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548ebcb5-fb37-4951-a780-6251ee3bd5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14014, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2e810d-9810-4b22-a990-b3cfdaecbc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6006, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20028bdf-d2dc-4301-b602-b57f26894210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34287141429998574"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.is_fraud.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a36a6ea1-59f1-4584-9a1c-9414f892daa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19996669996669997"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tst.is_fraud.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc72e90-696c-4de9-be88-63b57e8c3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_, mask = concat(df_tr, df_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6646cd8-28e4-4e5b-91fd-448380827fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_down = build_graph_tripartite(df_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1736243-ad85-4ca6-b8bc-aab543385c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40040, 21656)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_down.number_of_edges(), G_down.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b4aa8a5-5345-49eb-9695-96ac96247dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = G_down.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d853c-4058-41af-be62-912caf57bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.StellarGraph(edges=edges, edge_type_column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac28c94-607d-4557-b2a7-b6fb48aa33c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de46925-15f1-4e83-9c1e-410701c28a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba205b-8984-4c09-8c94-ec478329610e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3a43a7b-30ff-4de4-98aa-bef38365830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n",
    "                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n",
    "                                                                      test_size=0.20, \n",
    "                                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "809c9986-abeb-4728-b0ce-c7d724cdf8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2995442057942058, 0.30182317682317683)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_labels).mean(), np.array(test_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ecbfefb-fd75-4b34-b45e-4e6f70cdcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs = list(G_down.edges)\n",
    "train_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()      \n",
    "train_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0768b6b-3dda-4fe3-9d0f-fc25919d1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stellargraph as sg\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator\n",
    "from stellargraph.layer import GraphSAGE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8913093-7042-4a5d-87c6-5f9e2c72a9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3324862/2906379029.py:1: DeprecationWarning: Constructing a StellarGraph directly from a NetworkX graph has been replaced by the `StellarGraph.from_networkx` function\n",
      "  graph = sg.StellarGraph(G_down)\n"
     ]
    }
   ],
   "source": [
    "graph = sg.StellarGraph(G_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a203bbe6-f531-4ca3-bb46-462865ff9818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc4d16-c679-4b53-96d5-69e63a5d5007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab4daf40-17bb-4ddc-a0ae-ddf7b5449d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f8302c37474fcc9e662b6d4a2f3b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/21656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:44<00:00,  4.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bcd73a4e-8f71-4e88-a243-5fe511db19e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "852f2aff-6892-4141-bc64-ece1056605e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32032, 128)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_embeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "938d25ef-80c3-4b30-bfd8-fdd6acc6361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.79964884e-03, 1.64067835e-01, 7.30881765e-02, ...,\n",
       "        1.81038718e-04, 1.96826290e-02, 6.05850630e-02],\n",
       "       [3.18445265e-04, 9.41526145e-02, 2.41454929e-01, ...,\n",
       "        5.79439476e-02, 9.22752500e-01, 2.49633682e-03],\n",
       "       [1.09851332e-02, 4.12013801e-03, 1.61135435e-01, ...,\n",
       "        1.24859456e-02, 2.32662242e-02, 1.07970215e-01],\n",
       "       ...,\n",
       "       [6.13867212e-03, 8.51532519e-02, 7.86146245e-07, ...,\n",
       "        6.33678436e-02, 7.13208392e-02, 2.39914820e-01],\n",
       "       [2.59715295e-03, 1.24797074e-03, 1.26128927e-01, ...,\n",
       "        7.45704547e-02, 2.37582775e-04, 2.18050033e-01],\n",
       "       [3.34992632e-02, 2.74142623e-03, 4.02400009e-02, ...,\n",
       "        2.08475683e-02, 4.62760888e-02, 3.03567946e-01]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c97993bb-2441-4d0a-b1f3-51ed3553edde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32032,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c28d33a-3d57-415c-ad26-0cda07b403e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "# DataFrame 합치기\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22d60509-09fd-4b78-8e71-9dbd99c3baa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_0</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>X_9</th>\n",
       "      <th>...</th>\n",
       "      <th>X_119</th>\n",
       "      <th>X_120</th>\n",
       "      <th>X_121</th>\n",
       "      <th>X_122</th>\n",
       "      <th>X_123</th>\n",
       "      <th>X_124</th>\n",
       "      <th>X_125</th>\n",
       "      <th>X_126</th>\n",
       "      <th>X_127</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.799649e-03</td>\n",
       "      <td>0.164068</td>\n",
       "      <td>7.308818e-02</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.037998</td>\n",
       "      <td>0.026417</td>\n",
       "      <td>0.030260</td>\n",
       "      <td>0.045050</td>\n",
       "      <td>0.047880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.082948</td>\n",
       "      <td>0.018060</td>\n",
       "      <td>0.041995</td>\n",
       "      <td>0.073492</td>\n",
       "      <td>0.011187</td>\n",
       "      <td>1.810387e-04</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>0.060585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.184453e-04</td>\n",
       "      <td>0.094153</td>\n",
       "      <td>2.414549e-01</td>\n",
       "      <td>0.016275</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.015268</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.331411</td>\n",
       "      <td>0.067376</td>\n",
       "      <td>0.061926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223335</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.041893</td>\n",
       "      <td>0.051856</td>\n",
       "      <td>0.191570</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>5.794395e-02</td>\n",
       "      <td>0.922752</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.098513e-02</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>1.611354e-01</td>\n",
       "      <td>0.548673</td>\n",
       "      <td>0.025099</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>0.094634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070138</td>\n",
       "      <td>0.038877</td>\n",
       "      <td>0.014588</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.205133</td>\n",
       "      <td>0.064290</td>\n",
       "      <td>1.248595e-02</td>\n",
       "      <td>0.023266</td>\n",
       "      <td>0.107970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.125533e-04</td>\n",
       "      <td>0.069008</td>\n",
       "      <td>2.394260e-02</td>\n",
       "      <td>0.038580</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.058848</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.168507</td>\n",
       "      <td>0.327026</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.015680</td>\n",
       "      <td>0.193011</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>4.044086e-02</td>\n",
       "      <td>0.065931</td>\n",
       "      <td>0.131638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.551593e-01</td>\n",
       "      <td>0.011703</td>\n",
       "      <td>4.802953e-02</td>\n",
       "      <td>0.020095</td>\n",
       "      <td>0.177149</td>\n",
       "      <td>0.022541</td>\n",
       "      <td>0.196618</td>\n",
       "      <td>0.041765</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.158181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233692</td>\n",
       "      <td>0.104250</td>\n",
       "      <td>0.091681</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.874027</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>3.469664e-05</td>\n",
       "      <td>0.015489</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32027</th>\n",
       "      <td>1.361575e+00</td>\n",
       "      <td>0.023050</td>\n",
       "      <td>1.305244e-01</td>\n",
       "      <td>0.504093</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.312939</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.049380</td>\n",
       "      <td>0.332058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.191192</td>\n",
       "      <td>0.356860</td>\n",
       "      <td>0.227310</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>1.307885e-01</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>0.041412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32028</th>\n",
       "      <td>9.765987e-07</td>\n",
       "      <td>0.037045</td>\n",
       "      <td>1.420536e-02</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.116524</td>\n",
       "      <td>0.065952</td>\n",
       "      <td>0.054716</td>\n",
       "      <td>0.154811</td>\n",
       "      <td>0.011176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130505</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.039672</td>\n",
       "      <td>0.052033</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.015103</td>\n",
       "      <td>2.027648e-08</td>\n",
       "      <td>0.016023</td>\n",
       "      <td>0.169818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32029</th>\n",
       "      <td>6.138672e-03</td>\n",
       "      <td>0.085153</td>\n",
       "      <td>7.861462e-07</td>\n",
       "      <td>0.099862</td>\n",
       "      <td>0.408811</td>\n",
       "      <td>0.021244</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.115799</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.317840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177379</td>\n",
       "      <td>0.565970</td>\n",
       "      <td>0.022457</td>\n",
       "      <td>0.043790</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>0.257367</td>\n",
       "      <td>6.336784e-02</td>\n",
       "      <td>0.071321</td>\n",
       "      <td>0.239915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32030</th>\n",
       "      <td>2.597153e-03</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>1.261289e-01</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.015120</td>\n",
       "      <td>0.108578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.496311</td>\n",
       "      <td>0.065650</td>\n",
       "      <td>0.007386</td>\n",
       "      <td>7.457045e-02</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.218050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32031</th>\n",
       "      <td>3.349926e-02</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>4.024000e-02</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.065571</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.112705</td>\n",
       "      <td>0.023244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138493</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>0.032122</td>\n",
       "      <td>0.063049</td>\n",
       "      <td>0.028025</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>2.084757e-02</td>\n",
       "      <td>0.046276</td>\n",
       "      <td>0.303568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32032 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                X_0       X_1           X_2       X_3       X_4       X_5  \\\n",
       "0      8.799649e-03  0.164068  7.308818e-02  0.007493  0.000196  0.037998   \n",
       "1      3.184453e-04  0.094153  2.414549e-01  0.016275  0.078201  0.015268   \n",
       "2      1.098513e-02  0.004120  1.611354e-01  0.548673  0.025099  0.001323   \n",
       "3      5.125533e-04  0.069008  2.394260e-02  0.038580  0.000345  0.058848   \n",
       "4      2.551593e-01  0.011703  4.802953e-02  0.020095  0.177149  0.022541   \n",
       "...             ...       ...           ...       ...       ...       ...   \n",
       "32027  1.361575e+00  0.023050  1.305244e-01  0.504093  0.014287  0.312939   \n",
       "32028  9.765987e-07  0.037045  1.420536e-02  0.026103  0.000017  0.116524   \n",
       "32029  6.138672e-03  0.085153  7.861462e-07  0.099862  0.408811  0.021244   \n",
       "32030  2.597153e-03  0.001248  1.261289e-01  0.000002  0.001143  0.248826   \n",
       "32031  3.349926e-02  0.002741  4.024000e-02  0.003076  0.000032  0.000168   \n",
       "\n",
       "            X_6       X_7       X_8       X_9  ...     X_119     X_120  \\\n",
       "0      0.026417  0.030260  0.045050  0.047880  ...  0.001140  0.082948   \n",
       "1      0.000326  0.331411  0.067376  0.061926  ...  0.223335  0.000269   \n",
       "2      0.005411  0.005461  0.021607  0.094634  ...  0.070138  0.038877   \n",
       "3      0.005284  0.168507  0.327026  0.002053  ...  0.001018  0.037014   \n",
       "4      0.196618  0.041765  0.000156  0.158181  ...  0.233692  0.104250   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "32027  0.000587  0.015945  0.049380  0.332058  ...  0.002336  0.000683   \n",
       "32028  0.065952  0.054716  0.154811  0.011176  ...  0.130505  0.006745   \n",
       "32029  0.006153  0.115799  0.000933  0.317840  ...  0.177379  0.565970   \n",
       "32030  0.006462  0.016343  0.015120  0.108578  ...  0.000021  0.000859   \n",
       "32031  0.065571  0.012371  0.112705  0.023244  ...  0.138493  0.010161   \n",
       "\n",
       "          X_121     X_122     X_123     X_124         X_125     X_126  \\\n",
       "0      0.018060  0.041995  0.073492  0.011187  1.810387e-04  0.019683   \n",
       "1      0.041893  0.051856  0.191570  0.000165  5.794395e-02  0.922752   \n",
       "2      0.014588  0.003246  0.205133  0.064290  1.248595e-02  0.023266   \n",
       "3      0.015680  0.193011  0.000812  0.001481  4.044086e-02  0.065931   \n",
       "4      0.091681  0.002522  0.874027  0.003707  3.469664e-05  0.015489   \n",
       "...         ...       ...       ...       ...           ...       ...   \n",
       "32027  0.191192  0.356860  0.227310  0.000661  1.307885e-01  0.023592   \n",
       "32028  0.039672  0.052033  0.125356  0.015103  2.027648e-08  0.016023   \n",
       "32029  0.022457  0.043790  0.059339  0.257367  6.336784e-02  0.071321   \n",
       "32030  0.000894  0.496311  0.065650  0.007386  7.457045e-02  0.000238   \n",
       "32031  0.032122  0.063049  0.028025  0.001975  2.084757e-02  0.046276   \n",
       "\n",
       "          X_127  label  \n",
       "0      0.060585      1  \n",
       "1      0.002496      0  \n",
       "2      0.107970      0  \n",
       "3      0.131638      0  \n",
       "4      0.005535      0  \n",
       "...         ...    ...  \n",
       "32027  0.041412      0  \n",
       "32028  0.169818      1  \n",
       "32029  0.239915      0  \n",
       "32030  0.218050      0  \n",
       "32031  0.303568      1  \n",
       "\n",
       "[32032 rows x 129 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "baeddafa-8966-4aa9-9e24-f3d7d4edb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bebcc89b-8afa-4cc4-8454-c4104ede043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240124_110704/\"\n"
     ]
    }
   ],
   "source": [
    "predictr = TabularPredictor(label='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0abbbf1-847b-4aca-81fa-2f47813c6f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240124_110704/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   623.47 GB / 982.82 GB (63.4%)\n",
      "Train Data Rows:    32032\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    25264.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.4 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 16.4 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.39s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.07804695304695304, Train Rows: 29532, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd7032fe50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5904\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd7032fe50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5904\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.726\t = Validation score   (accuracy)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.7248\t = Validation score   (accuracy)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7236\t = Validation score   (accuracy)\n",
      "\t6.19s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7248\t = Validation score   (accuracy)\n",
      "\t8.16s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7268\t = Validation score   (accuracy)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7288\t = Validation score   (accuracy)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.726\t = Validation score   (accuracy)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 5: early stopping\n",
      "\t0.742\t = Validation score   (accuracy)\n",
      "\t14.83s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7244\t = Validation score   (accuracy)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7432\t = Validation score   (accuracy)\n",
      "\t11.94s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.7268\t = Validation score   (accuracy)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7532\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 52.58s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240124_110704/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7fcd0b85c640>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.fit(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c41dcc1-f573-4fc8-8776-fad60bb77974",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b97d0293-7e0a-48e2-9132-21b5986f5c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8008, 128)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d3e2436-05f4-4fb2-883e-2c5cf7fbc8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X_0       X_1       X_2       X_3       X_4       X_5       X_6  \\\n",
      "0  0.413663  2.075492  0.097850  0.431519  0.026412  0.046006  0.139835   \n",
      "1  0.012225  0.000547  0.024713  0.703247  0.020913  0.419119  0.352671   \n",
      "2  0.195774  0.000752  0.009002  0.204248  0.070720  0.906959  0.507191   \n",
      "3  0.260361  0.329479  0.229454  0.023667  0.001113  0.002806  0.034591   \n",
      "4  0.427026  0.024197  0.695513  0.057896  0.270117  0.026265  0.320806   \n",
      "\n",
      "        X_7       X_8       X_9  ...     X_118     X_119     X_120     X_121  \\\n",
      "0  0.014063  0.473687  0.014283  ...  0.048837  0.010120  0.005523  0.961210   \n",
      "1  1.669539  0.126232  0.027797  ...  0.728475  0.378981  1.377197  0.203648   \n",
      "2  0.267592  0.115088  0.409537  ...  0.295417  0.440117  0.088578  0.060138   \n",
      "3  0.045546  0.623125  0.282554  ...  0.174775  0.159482  0.001048  0.035379   \n",
      "4  0.029051  0.263759  0.028128  ...  0.008239  0.063498  0.810952  0.013463   \n",
      "\n",
      "      X_122     X_123     X_124     X_125     X_126     X_127  \n",
      "0  0.026908  0.000516  0.054398  0.188361  0.007897  0.495728  \n",
      "1  0.086590  0.230660  0.000614  1.211448  0.513626  0.000002  \n",
      "2  0.004575  1.479674  0.131626  0.928811  0.315709  0.000010  \n",
      "3  0.640979  0.329148  0.003226  0.278314  0.002369  0.150809  \n",
      "4  0.295149  0.006146  0.608962  0.076195  0.106696  0.122096  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)\n",
    "\n",
    "# DataFrame 확인\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09b3db14-438a-4fc0-9bda-9812158ed1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd8f12cb80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0241008991008991"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.predict(test_df).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43f79e21-3e23-4f1c-b371-d4c063467917",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8aadf5b2-1318-4f50-9125-999b2e26cf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd0b8c03a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "yhat = predictr.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c99cac54-31f4-4e25-af6c-6881ea6e3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87e0faab-3a97-48a7-a8db-abc98b6cf7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.690684</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>0.03955</td>\n",
       "      <td>0.498058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.690684         0.264249      0.021375   0.03955       0.498058"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7c6820-a8d2-493b-a623-80f247e38d7f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee76e9-1ceb-4b66-8e36-703285ce0d4b",
   "metadata": {},
   "source": [
    "### 0.3 / 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b3556f3-fd88-47c9-bdb9-d6c5e781e0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94eac3e460c8437aaec19404609b3c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/21656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:46<00:00,  4.61s/it]\n"
     ]
    }
   ],
   "source": [
    "df = throw(df, 0.3)\n",
    "\n",
    "df_tr, df_tst = split_dataframe(df, 0.3)\n",
    "\n",
    "df_, mask = concat(df_tr, df_tst)\n",
    "\n",
    "G_down = build_graph_tripartite(df_)\n",
    "\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n",
    "                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n",
    "                                                                      test_size=0.20, \n",
    "                                                                      random_state=42)\n",
    "\n",
    "edgs = list(G_down.edges)\n",
    "train_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()      \n",
    "train_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)\n",
    "\n",
    "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "# DataFrame 합치기\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "\n",
    "\n",
    "label = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d35423d1-65ad-4011-8910-0fadea52218e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240124_112803/\"\n"
     ]
    }
   ],
   "source": [
    "predictr = TabularPredictor(label='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "598b2054-7930-4baa-b0bf-ad0ce54e71a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240124_112803/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   622.65 GB / 982.82 GB (63.4%)\n",
      "Train Data Rows:    32032\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24167.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.4 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 16.4 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.38s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.07804695304695304, Train Rows: 29532, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd0b8c00d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.594\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd0b8c00d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5956\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.7392\t = Validation score   (accuracy)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.74\t = Validation score   (accuracy)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7304\t = Validation score   (accuracy)\n",
      "\t6.74s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7268\t = Validation score   (accuracy)\n",
      "\t8.77s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7396\t = Validation score   (accuracy)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7328\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7312\t = Validation score   (accuracy)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 4: early stopping\n",
      "\t0.758\t = Validation score   (accuracy)\n",
      "\t14.33s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7376\t = Validation score   (accuracy)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7464\t = Validation score   (accuracy)\n",
      "\t10.13s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.738\t = Validation score   (accuracy)\n",
      "\t2.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7708\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 52.42s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240124_112803/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7fcd8f0e0190>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictr.fit(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7d42841-77f3-4717-8f42-09d0c2236b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d27b75e-6ad6-4e5e-b38a-f82ab4604787",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "abc751f2-30ce-45fe-be65-832ebb0bd8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fccf01554c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "y = np.array(test_labels)\n",
    "\n",
    "yhat = predictr.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883acde7-9d70-45de-b822-d0a36a72c487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "795bbb76-fe2f-4182-8628-38c2aaab79ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.69493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0         0.69493              0.0           0.0       0.0            0.5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e5b8e3-37d3-4e4e-8984-87357c13e5f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce14bf-4c59-47a6-aaf7-28383767a1bc",
   "metadata": {},
   "source": [
    "### 0.3 / 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d25e7de-4dbb-4096-a6f8-cf8eb5ee0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Desktop/fraudTrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "83c8108a-6599-45ac-ae4a-3efa69f7863a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e749c5a4d2ea48caaf1993a19c01804a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/21656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:48<00:00,  4.86s/it]\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240124_113911/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240124_113911/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   621.83 GB / 982.82 GB (63.3%)\n",
      "Train Data Rows:    32032\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    23867.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.4 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 16.4 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.07804695304695304, Train Rows: 29532, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd0b85e940>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5988\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd0b85e8b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5992\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.738\t = Validation score   (accuracy)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.738\t = Validation score   (accuracy)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7324\t = Validation score   (accuracy)\n",
      "\t6.23s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7292\t = Validation score   (accuracy)\n",
      "\t8.22s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7364\t = Validation score   (accuracy)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7372\t = Validation score   (accuracy)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7324\t = Validation score   (accuracy)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 8: early stopping\n",
      "\t0.756\t = Validation score   (accuracy)\n",
      "\t15.57s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7352\t = Validation score   (accuracy)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7552\t = Validation score   (accuracy)\n",
      "\t10.67s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.738\t = Validation score   (accuracy)\n",
      "\t2.21s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7688\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 52.62s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240124_113911/\")\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd0b85e790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.688686</td>\n",
       "      <td>0.350318</td>\n",
       "      <td>0.045852</td>\n",
       "      <td>0.081091</td>\n",
       "      <td>0.504741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.688686         0.350318      0.045852  0.081091       0.504741"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = throw(df, 0.3)\n",
    "df_tr, df_tst = split_dataframe(df, 0.4)\n",
    "df_, mask = concat(df_tr, df_tst)\n",
    "G_down = build_graph_tripartite(df_)\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n",
    "                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n",
    "                                                                      test_size=0.20, \n",
    "                                                                      random_state=42)\n",
    "edgs = list(G_down.edges)\n",
    "train_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()      \n",
    "train_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)\n",
    "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "label = np.array(train_labels)\n",
    "\n",
    "predictr = TabularPredictor(label='label')\n",
    "\n",
    "predictr.fit(df) \n",
    "\n",
    "test = np.array(test_embeddings)\n",
    "\n",
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)\n",
    "\n",
    "y = np.array(test_labels)\n",
    "yhat = predictr.predict(test_df)\n",
    "\n",
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5770a2b7-e437-4fc1-a802-52c0b56cc642",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d417f2a-168e-408a-b41a-9fd877799c46",
   "metadata": {},
   "source": [
    "### 0.4 / 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08fbc28b-6fea-4fb9-9e11-64441408e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Desktop/fraudTrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "de3a5c82-614e-43ef-8e37-833125088714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15f8a75ac454ffa816a6801db9f939f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/16650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:32<00:00,  3.23s/it]\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240125_002023/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240125_002023/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   620.00 GB / 982.82 GB (63.1%)\n",
      "Train Data Rows:    24024\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24334.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 12.3 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 12.3 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.7s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 21621, Val Rows: 2403\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd0b85e1f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5568\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fccf82ed550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5576\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.6746\t = Validation score   (accuracy)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6767\t = Validation score   (accuracy)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6479\t = Validation score   (accuracy)\n",
      "\t4.39s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6583\t = Validation score   (accuracy)\n",
      "\t6.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.6804\t = Validation score   (accuracy)\n",
      "\t6.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6558\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6533\t = Validation score   (accuracy)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 7: early stopping\n",
      "\t0.7012\t = Validation score   (accuracy)\n",
      "\t11.36s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6866\t = Validation score   (accuracy)\n",
      "\t2.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.707\t = Validation score   (accuracy)\n",
      "\t7.38s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6758\t = Validation score   (accuracy)\n",
      "\t3.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7179\t = Validation score   (accuracy)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 49.84s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240125_002023/\")\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd700e30d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.599234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.599234              0.0           0.0       0.0       0.499584"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = throw(df, 0.4)\n",
    "df_tr, df_tst = split_dataframe(df, 0.4)\n",
    "df_, mask = concat(df_tr, df_tst)\n",
    "G_down = build_graph_tripartite(df_)\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n",
    "                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n",
    "                                                                      test_size=0.20, \n",
    "                                                                      random_state=42)\n",
    "edgs = list(G_down.edges)\n",
    "train_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()      \n",
    "train_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)\n",
    "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "label = np.array(train_labels)\n",
    "\n",
    "predictr = TabularPredictor(label='label')\n",
    "\n",
    "predictr.fit(df) \n",
    "\n",
    "test = np.array(test_embeddings)\n",
    "\n",
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)\n",
    "\n",
    "y = np.array(test_labels)\n",
    "yhat = predictr.predict(test_df)\n",
    "\n",
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c624b1ea-377b-476c-9648-66ea39768cf1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3540f-0081-4b51-b44c-360ff35f9c8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 0.4 / 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03187435-3dd8-481c-b615-e5771ce6e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Desktop/fraudTrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6157f044-2332-4850-a051-725ea3264d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fb4943699041c6b02f6b074936d9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/16650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:32<00:00,  3.28s/it]\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240125_002828/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240125_002828/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   619.33 GB / 982.82 GB (63.0%)\n",
      "Train Data Rows:    24024\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24266.65 MB\n",
      "\tTrain Data (Original)  Memory Usage: 12.3 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 12.3 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 21621, Val Rows: 2403\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcb208ff4c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5389\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcb208ff4c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5397\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.6833\t = Validation score   (accuracy)\n",
      "\t1.88s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6758\t = Validation score   (accuracy)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6629\t = Validation score   (accuracy)\n",
      "\t4.52s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6633\t = Validation score   (accuracy)\n",
      "\t6.25s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.6733\t = Validation score   (accuracy)\n",
      "\t2.82s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6604\t = Validation score   (accuracy)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6579\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 8: early stopping\n",
      "\t0.6991\t = Validation score   (accuracy)\n",
      "\t11.81s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6779\t = Validation score   (accuracy)\n",
      "\t2.21s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6937\t = Validation score   (accuracy)\n",
      "\t9.84s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6821\t = Validation score   (accuracy)\n",
      "\t4.86s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7116\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 50.43s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240125_002828/\")\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd700e3af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594406</td>\n",
       "      <td>0.464115</td>\n",
       "      <td>0.040066</td>\n",
       "      <td>0.073764</td>\n",
       "      <td>0.504412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.594406         0.464115      0.040066  0.073764       0.504412"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = throw(df, 0.4)\n",
    "df_tr, df_tst = split_dataframe(df, 0.3)\n",
    "df_, mask = concat(df_tr, df_tst)\n",
    "G_down = build_graph_tripartite(df_)\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n",
    "                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n",
    "                                                                      test_size=0.20, \n",
    "                                                                      random_state=42)\n",
    "edgs = list(G_down.edges)\n",
    "train_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()      \n",
    "train_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)\n",
    "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "label = np.array(train_labels)\n",
    "\n",
    "predictr = TabularPredictor(label='label')\n",
    "\n",
    "predictr.fit(df) \n",
    "\n",
    "test = np.array(test_embeddings)\n",
    "\n",
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)\n",
    "\n",
    "y = np.array(test_labels)\n",
    "yhat = predictr.predict(test_df)\n",
    "\n",
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc390c3a-b576-417f-a1dd-8afb6d8fa4b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e9d9d-efea-4f1a-a15e-616e1bd37af3",
   "metadata": {},
   "source": [
    "### 0.5 / 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b9ffa0cd-fc2f-4e9f-8662-f79eff5c8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Desktop/fraudTrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "74782799-95d4-472c-a350-f9822d1d57e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d36f4cd7eb478ebf48ee45bb7056bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/13641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:25<00:00,  2.54s/it]\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240125_004947/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240125_004947/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   617.43 GB / 982.82 GB (62.8%)\n",
      "Train Data Rows:    19219\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24477.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.84 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.84 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.69s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 17297, Val Rows: 1922\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd8f2fa700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5484\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd8f2fa700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5484\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.6556\t = Validation score   (accuracy)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6493\t = Validation score   (accuracy)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6379\t = Validation score   (accuracy)\n",
      "\t3.71s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6415\t = Validation score   (accuracy)\n",
      "\t5.18s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.6545\t = Validation score   (accuracy)\n",
      "\t2.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6332\t = Validation score   (accuracy)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6498\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 4: early stopping\n",
      "\t0.6597\t = Validation score   (accuracy)\n",
      "\t9.97s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.629\t = Validation score   (accuracy)\n",
      "\t1.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6514\t = Validation score   (accuracy)\n",
      "\t5.69s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6472\t = Validation score   (accuracy)\n",
      "\t3.91s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6769\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 39.24s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240125_004947/\")\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fccf0308310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508637</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.499854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.508637         0.470588       0.00339  0.006731       0.499854"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = throw(df, 0.5)\n",
    "df_tr, df_tst = split_dataframe(df, 0.3)\n",
    "df_, mask = concat(df_tr, df_tst)\n",
    "G_down = build_graph_tripartite(df_)\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n",
    "                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n",
    "                                                                      test_size=0.20, \n",
    "                                                                      random_state=42)\n",
    "edgs = list(G_down.edges)\n",
    "train_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()      \n",
    "train_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)\n",
    "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "label = np.array(train_labels)\n",
    "\n",
    "predictr = TabularPredictor(label='label')\n",
    "\n",
    "predictr.fit(df) \n",
    "\n",
    "test = np.array(test_embeddings)\n",
    "\n",
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)\n",
    "\n",
    "y = np.array(test_labels)\n",
    "yhat = predictr.predict(test_df)\n",
    "\n",
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af0e166-59aa-44d8-a04e-25a753d1b1b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f23ee0-a7dd-4648-9a97-8c5459511cf2",
   "metadata": {},
   "source": [
    "### 0.5 / 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a99a0574-3280-4fdf-b3db-2feb157ccfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Desktop/fraudTrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5fcdbcfe-a49c-4aa1-9e41-98d4625ab89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf33661ec7b4f28beb63b4b2dafa2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/13641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:25<00:00,  2.57s/it]\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240125_004313/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240125_004313/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   617.99 GB / 982.82 GB (62.9%)\n",
      "Train Data Rows:    19219\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24485.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.84 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.84 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.68s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 17297, Val Rows: 1922\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fccf87d4790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5375\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fccf87d4e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5375\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.6774\t = Validation score   (accuracy)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.667\t = Validation score   (accuracy)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6592\t = Validation score   (accuracy)\n",
      "\t3.68s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6623\t = Validation score   (accuracy)\n",
      "\t5.2s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.6727\t = Validation score   (accuracy)\n",
      "\t3.06s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6649\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6686\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 5: early stopping\n",
      "\t0.6649\t = Validation score   (accuracy)\n",
      "\t10.27s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6582\t = Validation score   (accuracy)\n",
      "\t1.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6727\t = Validation score   (accuracy)\n",
      "\t5.93s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6681\t = Validation score   (accuracy)\n",
      "\t3.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6915\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 40.32s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240125_004313/\")\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcd8f2579d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.501977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.501977              0.0           0.0       0.0            0.5"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = throw(df, 0.5)\n",
    "df_tr, df_tst = split_dataframe(df, 0.4)\n",
    "df_, mask = concat(df_tr, df_tst)\n",
    "G_down = build_graph_tripartite(df_)\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n",
    "                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n",
    "                                                                      test_size=0.20, \n",
    "                                                                      random_state=42)\n",
    "edgs = list(G_down.edges)\n",
    "train_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()      \n",
    "train_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)\n",
    "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "label = np.array(train_labels)\n",
    "\n",
    "predictr = TabularPredictor(label='label')\n",
    "\n",
    "predictr.fit(df) \n",
    "\n",
    "test = np.array(test_embeddings)\n",
    "\n",
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)\n",
    "\n",
    "y = np.array(test_labels)\n",
    "yhat = predictr.predict(test_df)\n",
    "\n",
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3826b-cf3b-41d8-b050-e03ff904be5f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6c7740-aed4-4433-b7d7-4d4c0e05de31",
   "metadata": {},
   "source": [
    "### 0.5 / 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4cc9ecf9-68ce-44d4-8573-456253fde31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Desktop/fraudTrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "44eaf174-ea25-4f9a-aa71-4e7a37bc9e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3359d84194145138237dc366e0da14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/13641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:25<00:00,  2.54s/it]\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240125_005617/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240125_005617/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   616.86 GB / 982.82 GB (62.8%)\n",
      "Train Data Rows:    19219\n",
      "Train Data Columns: 128\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24455.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.84 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['X_0', 'X_1', 'X_2', 'X_3', 'X_4', ...]\n",
      "\t0.6s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.84 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.65s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 17297, Val Rows: 1922\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcb208fbca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5182\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fcb208fbca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\t0.5193\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.6348\t = Validation score   (accuracy)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6348\t = Validation score   (accuracy)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6254\t = Validation score   (accuracy)\n",
      "\t3.74s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6337\t = Validation score   (accuracy)\n",
      "\t5.22s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.6462\t = Validation score   (accuracy)\n",
      "\t3.83s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6384\t = Validation score   (accuracy)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6446\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 8: early stopping\n",
      "\t0.6426\t = Validation score   (accuracy)\n",
      "\t9.51s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6301\t = Validation score   (accuracy)\n",
      "\t1.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6415\t = Validation score   (accuracy)\n",
      "\t5.31s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6379\t = Validation score   (accuracy)\n",
      "\t2.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6634\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 38.72s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240125_005617/\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.510926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "0        0.510926              0.0           0.0       0.0       0.499796"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = throw(df, 0.5)\n",
    "df_tr, df_tst = split_dataframe(df, 0.2)\n",
    "df_, mask = concat(df_tr, df_tst)\n",
    "G_down = build_graph_tripartite(df_)\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_down.edges))), \n",
    "                                                                      list(nx.get_edge_attributes(G_down, \"label\").values()), \n",
    "                                                                      test_size=0.20, \n",
    "                                                                      random_state=42)\n",
    "edgs = list(G_down.edges)\n",
    "train_graph = G_down.edge_subgraph([edgs[x] for x in train_edges]).copy()      \n",
    "train_graph.add_nodes_from(list(set(G_down.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)\n",
    "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv) \n",
    "\n",
    "train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "columns = [f'X_{i}' for i in range(np.array(train_embeddings).shape[1])]\n",
    "df_data = pd.DataFrame(data=train_embeddings, columns=columns)\n",
    "df_labels = pd.DataFrame(data=train_labels, columns=['label'])\n",
    "\n",
    "df = pd.concat([df_data, df_labels], axis=1)\n",
    "label = np.array(train_labels)\n",
    "\n",
    "predictr = TabularPredictor(label='label')\n",
    "\n",
    "predictr.fit(df) \n",
    "\n",
    "test = np.array(test_embeddings)\n",
    "\n",
    "columns = [f'X_{i}' for i in range(test.shape[1])]\n",
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(data=test, columns=columns)\n",
    "\n",
    "y = np.array(test_labels)\n",
    "yhat = predictr.predict(test_df)\n",
    "\n",
    "evaluation(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8a0d0-8138-49f3-b213-db247e81ed09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
