{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c8593b37-a6e6-4ccb-b9b2-349f55cb2b69",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"[FRAUD] 책_코드 함수 만들기\"\n",
    "author: \"김보람\"\n",
    "date: \"04/04/2024\"\n",
    "categories:\n",
    "  - graph\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eedf6e-cd2a-40f0-aac9-e8899d5b1acc",
   "metadata": {},
   "source": [
    "# FAURD코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8812aa9-c507-4520-9dfc-38a88301f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import pickle \n",
    "import time \n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# sklearn\n",
    "from sklearn import model_selection # split함수이용\n",
    "from sklearn import ensemble # RF,GBM\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# gnn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01fbd14-ccf1-4fca-b40d-b465036e21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample_textbook(df):\n",
    "    df_majority = df[df.is_fraud==0].copy()\n",
    "    df_minority = df[df.is_fraud==1].copy()\n",
    "    df_maj_dowsampled = sklearn.utils.resample(df_majority, n_samples=len(df_minority), replace=False, random_state=42)\n",
    "    df_downsampled = pd.concat([df_minority, df_maj_dowsampled])\n",
    "    return df_downsampled\n",
    "\n",
    "def compute_time_difference(group):\n",
    "    n = len(group)\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            time_difference = abs(group.iloc[i].trans_date_trans_time.value - group.iloc[j].trans_date_trans_time.value)\n",
    "            result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n",
    "    return result\n",
    "\n",
    "def mask(df):\n",
    "    df_tr,df_test = sklearn.model_selection.train_test_split(df, random_state=42)\n",
    "    N = len(df)\n",
    "    train_mask = [i in df_tr.index for i in range(N)]\n",
    "    test_mask = [i in df_test.index for i in range(N)]\n",
    "    train_mask = np.array(train_mask)\n",
    "    test_mask = np.array(test_mask)\n",
    "    return train_mask, test_mask\n",
    "\n",
    "def edge_index_selected(edge_index):\n",
    "    theta = edge_index[:,2].mean()\n",
    "    edge_index[:,2] = (np.exp(-edge_index[:,2]/theta) != 1)*(np.exp(-edge_index[:,2]/theta))\n",
    "    edge_index = edge_index.tolist()\n",
    "    mean_ = np.array(edge_index)[:,2].mean()\n",
    "    selected_edges = [(int(row[0]), int(row[1])) for row in edge_index if row[2] > mean_]\n",
    "    edge_index_selected = torch.tensor(selected_edges, dtype=torch.long).t()\n",
    "    return edge_index_selected\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00abe65e-e827-4a77-98d1-a1541c76b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../fraudTrain.pkl', 'rb') as file:\n",
    "    fraudTrain = pickle.load(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6dd5e82-f16f-479c-8280-d5d0dcf3f075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2.703190e+15</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>6.304230e+11</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>3.885950e+13</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:00</td>\n",
       "      <td>3.534090e+15</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:00</td>\n",
       "      <td>3.755340e+14</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>2020-03-10 16:07:00</td>\n",
       "      <td>6.011980e+15</td>\n",
       "      <td>fraud_Fadel Inc</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>77.00</td>\n",
       "      <td>Haley</td>\n",
       "      <td>Wagner</td>\n",
       "      <td>F</td>\n",
       "      <td>05561 Farrell Crescent</td>\n",
       "      <td>Annapolis</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0305</td>\n",
       "      <td>-76.5515</td>\n",
       "      <td>92106</td>\n",
       "      <td>Accountant, chartered certified</td>\n",
       "      <td>1943-05-28</td>\n",
       "      <td>45ecd198c65e81e597db22e8d2ef7361</td>\n",
       "      <td>1362931649</td>\n",
       "      <td>38.779464</td>\n",
       "      <td>-76.317042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>2020-03-10 16:07:00</td>\n",
       "      <td>4.839040e+15</td>\n",
       "      <td>fraud_Cremin, Hamill and Reichel</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>116.94</td>\n",
       "      <td>Meredith</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>F</td>\n",
       "      <td>043 Hanson Turnpike</td>\n",
       "      <td>Hedrick</td>\n",
       "      <td>...</td>\n",
       "      <td>41.1826</td>\n",
       "      <td>-92.3097</td>\n",
       "      <td>1583</td>\n",
       "      <td>Geochemist</td>\n",
       "      <td>1999-06-28</td>\n",
       "      <td>c00ce51c6ebb7657474a77b9e0b51f34</td>\n",
       "      <td>1362931670</td>\n",
       "      <td>41.400318</td>\n",
       "      <td>-92.726724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>2020-03-10 16:08:00</td>\n",
       "      <td>5.718440e+11</td>\n",
       "      <td>fraud_O'Connell, Botsford and Hand</td>\n",
       "      <td>home</td>\n",
       "      <td>21.27</td>\n",
       "      <td>Susan</td>\n",
       "      <td>Mills</td>\n",
       "      <td>F</td>\n",
       "      <td>005 Cody Estates</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>...</td>\n",
       "      <td>38.2507</td>\n",
       "      <td>-85.7476</td>\n",
       "      <td>736284</td>\n",
       "      <td>Engineering geologist</td>\n",
       "      <td>1952-04-02</td>\n",
       "      <td>17c9dc8b2a6449ca2473726346e58e6c</td>\n",
       "      <td>1362931711</td>\n",
       "      <td>37.293339</td>\n",
       "      <td>-84.798122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>2020-03-10 16:08:00</td>\n",
       "      <td>4.646850e+18</td>\n",
       "      <td>fraud_Thompson-Gleason</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>9.52</td>\n",
       "      <td>Julia</td>\n",
       "      <td>Bell</td>\n",
       "      <td>F</td>\n",
       "      <td>576 House Crossroad</td>\n",
       "      <td>West Sayville</td>\n",
       "      <td>...</td>\n",
       "      <td>40.7320</td>\n",
       "      <td>-73.1000</td>\n",
       "      <td>4056</td>\n",
       "      <td>Film/video editor</td>\n",
       "      <td>1990-06-25</td>\n",
       "      <td>5ca650881b48a6a38754f841c23b77ab</td>\n",
       "      <td>1362931718</td>\n",
       "      <td>39.773077</td>\n",
       "      <td>-72.213209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>2020-03-10 16:08:00</td>\n",
       "      <td>2.283740e+15</td>\n",
       "      <td>fraud_Buckridge PLC</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>6.81</td>\n",
       "      <td>Shannon</td>\n",
       "      <td>Williams</td>\n",
       "      <td>F</td>\n",
       "      <td>9345 Spencer Junctions Suite 183</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0770</td>\n",
       "      <td>-84.3033</td>\n",
       "      <td>165556</td>\n",
       "      <td>Prison officer</td>\n",
       "      <td>1997-12-27</td>\n",
       "      <td>8d0a575fe635bbde12f1a2bffc126731</td>\n",
       "      <td>1362931730</td>\n",
       "      <td>33.601468</td>\n",
       "      <td>-83.891921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trans_date_trans_time        cc_num  \\\n",
       "0         2019-01-01 00:00:00  2.703190e+15   \n",
       "1         2019-01-01 00:00:00  6.304230e+11   \n",
       "2         2019-01-01 00:00:00  3.885950e+13   \n",
       "3         2019-01-01 00:01:00  3.534090e+15   \n",
       "4         2019-01-01 00:03:00  3.755340e+14   \n",
       "...                       ...           ...   \n",
       "1048570   2020-03-10 16:07:00  6.011980e+15   \n",
       "1048571   2020-03-10 16:07:00  4.839040e+15   \n",
       "1048572   2020-03-10 16:08:00  5.718440e+11   \n",
       "1048573   2020-03-10 16:08:00  4.646850e+18   \n",
       "1048574   2020-03-10 16:08:00  2.283740e+15   \n",
       "\n",
       "                                   merchant        category     amt  \\\n",
       "0                fraud_Rippin, Kub and Mann        misc_net    4.97   \n",
       "1           fraud_Heller, Gutmann and Zieme     grocery_pos  107.23   \n",
       "2                      fraud_Lind-Buckridge   entertainment  220.11   \n",
       "3        fraud_Kutch, Hermiston and Farrell   gas_transport   45.00   \n",
       "4                       fraud_Keeling-Crist        misc_pos   41.96   \n",
       "...                                     ...             ...     ...   \n",
       "1048570                     fraud_Fadel Inc  health_fitness   77.00   \n",
       "1048571    fraud_Cremin, Hamill and Reichel        misc_pos  116.94   \n",
       "1048572  fraud_O'Connell, Botsford and Hand            home   21.27   \n",
       "1048573              fraud_Thompson-Gleason  health_fitness    9.52   \n",
       "1048574                 fraud_Buckridge PLC        misc_pos    6.81   \n",
       "\n",
       "             first      last gender                            street  \\\n",
       "0         Jennifer     Banks      F                    561 Perry Cove   \n",
       "1        Stephanie      Gill      F      43039 Riley Greens Suite 393   \n",
       "2           Edward   Sanchez      M          594 White Dale Suite 530   \n",
       "3           Jeremy     White      M       9443 Cynthia Court Apt. 038   \n",
       "4            Tyler    Garcia      M                  408 Bradley Rest   \n",
       "...            ...       ...    ...                               ...   \n",
       "1048570      Haley    Wagner      F            05561 Farrell Crescent   \n",
       "1048571   Meredith  Campbell      F               043 Hanson Turnpike   \n",
       "1048572      Susan     Mills      F                  005 Cody Estates   \n",
       "1048573      Julia      Bell      F               576 House Crossroad   \n",
       "1048574    Shannon  Williams      F  9345 Spencer Junctions Suite 183   \n",
       "\n",
       "                   city  ...      lat      long  city_pop  \\\n",
       "0        Moravian Falls  ...  36.0788  -81.1781      3495   \n",
       "1                Orient  ...  48.8878 -118.2105       149   \n",
       "2            Malad City  ...  42.1808 -112.2620      4154   \n",
       "3               Boulder  ...  46.2306 -112.1138      1939   \n",
       "4              Doe Hill  ...  38.4207  -79.4629        99   \n",
       "...                 ...  ...      ...       ...       ...   \n",
       "1048570       Annapolis  ...  39.0305  -76.5515     92106   \n",
       "1048571         Hedrick  ...  41.1826  -92.3097      1583   \n",
       "1048572      Louisville  ...  38.2507  -85.7476    736284   \n",
       "1048573   West Sayville  ...  40.7320  -73.1000      4056   \n",
       "1048574      Alpharetta  ...  34.0770  -84.3033    165556   \n",
       "\n",
       "                                       job         dob  \\\n",
       "0                Psychologist, counselling  1988-03-09   \n",
       "1        Special educational needs teacher  1978-06-21   \n",
       "2              Nature conservation officer  1962-01-19   \n",
       "3                          Patent attorney  1967-01-12   \n",
       "4           Dance movement psychotherapist  1986-03-28   \n",
       "...                                    ...         ...   \n",
       "1048570    Accountant, chartered certified  1943-05-28   \n",
       "1048571                         Geochemist  1999-06-28   \n",
       "1048572              Engineering geologist  1952-04-02   \n",
       "1048573                  Film/video editor  1990-06-25   \n",
       "1048574                     Prison officer  1997-12-27   \n",
       "\n",
       "                                trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0        0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1        1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2        a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3        6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4        a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "...                                   ...         ...        ...         ...   \n",
       "1048570  45ecd198c65e81e597db22e8d2ef7361  1362931649  38.779464  -76.317042   \n",
       "1048571  c00ce51c6ebb7657474a77b9e0b51f34  1362931670  41.400318  -92.726724   \n",
       "1048572  17c9dc8b2a6449ca2473726346e58e6c  1362931711  37.293339  -84.798122   \n",
       "1048573  5ca650881b48a6a38754f841c23b77ab  1362931718  39.773077  -72.213209   \n",
       "1048574  8d0a575fe635bbde12f1a2bffc126731  1362931730  33.601468  -83.891921   \n",
       "\n",
       "         is_fraud  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "1048570         0  \n",
       "1048571         0  \n",
       "1048572         0  \n",
       "1048573         0  \n",
       "1048574         0  \n",
       "\n",
       "[1048575 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fraudTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ec0330-c92d-494f-b47b-2cb0dcde110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../function_proposed_gcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2843d90-bbe5-4e3c-98a4-a63f8f099439",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../functions-book.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164c1db-7c0d-4ed6-8dee-7c48f7ff1198",
   "metadata": {},
   "source": [
    "## 데이터정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd7e2cc5-dd94-4462-a43b-3e2c19f65fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df50 = throw(fraudTrain, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e987e34-1467-4608-918b-a4988910abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask = mask(df50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede10437-7a8b-4b83-936f-41ff40cf2e6d",
   "metadata": {},
   "source": [
    "# 책(신용카드 거래에 대한 그래프 분석)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472937e-ac8d-45ab-8d26-454bbbf76c3d",
   "metadata": {},
   "source": [
    "`-` 이분그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "44f78797-91db-4943-880f-625f41ff87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_bipartite(df_input, graph_type=nx.Graph()):\n",
    "    df=df_input.copy()\n",
    "    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n",
    "                                                      df[\"merchant\"].values.tolist()))}\n",
    "    \n",
    "    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n",
    "    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n",
    "    \n",
    "    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n",
    "    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x>0 else 0)\n",
    "    \n",
    "    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n",
    "    \n",
    "    nx.set_edge_attributes(G, {(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부 \n",
    "    \n",
    "    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5d7d24d3-ddc9-4573-b411-b787f47239af",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_bu = build_graph_bipartite(df50, nx.Graph(name=\"Bipartite Undirect\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5f718-5b3e-4c30-8d67-f30a737143bb",
   "metadata": {},
   "source": [
    "`-` 삼분그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de4f50b6-213c-4b04-b3bd-4ff0a8221ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_tripartite(df_input, graph_type=nx.Graph()):\n",
    "    df=df_input.copy()\n",
    "    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n",
    "                                                       df[\"cc_num\"].values.tolist() +\n",
    "                                                       df[\"merchant\"].values.tolist()))}\n",
    "    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n",
    "    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n",
    "    \n",
    "        \n",
    "    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n",
    "                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")\n",
    "     \n",
    "    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n",
    "    \n",
    "    \n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027823d-ca18-439f-9bea-54460f7d7e70",
   "metadata": {},
   "source": [
    "- 판매자, 고객, 거래에 노드 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2be1fed8-bc99-46cd-8946-78e5edffb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_tu = build_graph_tripartite(df50, nx.Graph())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb33a5-23a8-4378-91ac-aedcca26ef9b",
   "metadata": {},
   "source": [
    "## 사기 탐지를 위한 지도 및 비지도 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d2633-61e6-4a0e-aee5-5d676f3bf563",
   "metadata": {},
   "source": [
    "### 지도학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "41785fd7-4d03-4c31-b75d-37ab2c196c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
    "\n",
    "\n",
    "def build_graph_bipartite(df_input, graph_type=nx.Graph()):\n",
    "    \"\"\"\n",
    "    Build a bipartite graph from the input dataframe.\n",
    "\n",
    "    Parameters:\n",
    "        df_input (DataFrame): Input dataframe containing transaction information.\n",
    "        graph_type (networkx graph type, optional): Type of graph to create. Defaults to nx.Graph().\n",
    "\n",
    "    Returns:\n",
    "        networkx.Graph: Bipartite graph.\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    mapping = {x: node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist() + df[\"merchant\"].values.tolist()))}\n",
    "    \n",
    "    df[\"from\"] = df[\"cc_num\"].apply(lambda x: mapping[x])  # 엣지의 출발점\n",
    "    df[\"to\"] = df[\"merchant\"].apply(lambda x: mapping[x])  # 엣지의 도착점\n",
    "    \n",
    "    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from', 'to']).agg({\"is_fraud\":\"sum\", \"amt\":\"sum\"}).reset_index()\n",
    "    df[\"is_fraud\"] = df[\"is_fraud\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    G = nx.from_edgelist(df[[\"from\", \"to\"]].values, create_using=graph_type)\n",
    "    \n",
    "    nx.set_edge_attributes(G, {(int(x[\"from\"]), int(x[\"to\"])): x[\"is_fraud\"] for idx, x in df[[\"from\", \"to\", \"is_fraud\"]].iterrows()}, \"label\")  # 엣지 속성 설정, 각 속성의 사기 여부\n",
    "    \n",
    "    nx.set_edge_attributes(G, {(int(x[\"from\"]), int(x[\"to\"])): x[\"amt\"] for idx, x in df[[\"from\", \"to\", \"amt\"]].iterrows()}, \"weight\")  # 엣지 속성 설정, 각 엣지의 거래 금액\n",
    "\n",
    "    return G\n",
    "\n",
    "def train_and_evaluate_node2vec(df, embedding_dimension=128, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Train and evaluate node2vec embeddings with a Random Forest classifier.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Input dataframe containing transaction information.\n",
    "        embedding_dimension (int, optional): Dimension of node embeddings. Defaults to 128.\n",
    "        test_size (float, optional): Proportion of the dataset to include in the test split. Defaults to 0.2.\n",
    "        random_state (int, optional): Seed used by the random number generator. Defaults to 42.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    G = build_graph_bipartite(df)\n",
    "    \n",
    "    train_edges, test_edges, train_labels, y = train_test_split(list(range(len(G.edges))), \n",
    "                                                                 list(nx.get_edge_attributes(G, \"label\").values()))\n",
    "    \n",
    "    edgs = list(G.edges)\n",
    "    train_graph = G.edge_subgraph([edgs[x] for x in train_edges]).copy()\n",
    "    train_graph.add_nodes_from(list(set(G.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "    node2vec_train = Node2Vec(train_graph, dimensions=embedding_dimension, weight_key='weight')\n",
    "    model_train = node2vec_train.fit(window=10)\n",
    "    \n",
    "    classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for cl in classes:\n",
    "        embeddings_train = cl(keyed_vectors=model_train.wv)\n",
    "\n",
    "        train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "        test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=1000, random_state=random_state)\n",
    "        rf.fit(train_embeddings, train_labels)\n",
    "\n",
    "        yhat = rf.predict(test_embeddings)\n",
    "        acc = metrics.accuracy_score(y, yhat)\n",
    "        pre = metrics.precision_score(y, yhat)\n",
    "        rec = metrics.recall_score(y, yhat)\n",
    "        f1 = metrics.f1_score(y, yhat)\n",
    "        auc = metrics.roc_auc_score(y, yhat)\n",
    "        \n",
    "        evaluation_results[cl.__name__] = {\"accuracy\": acc, \"precision\": pre, \"recall\": rec, \"f1-score\": f1, \"auc\": auc}\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "# Example usage:\n",
    "# evaluation_results = train_and_evaluate_node2vec(df50)\n",
    "# print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d895bfd6-7f14-4ccd-80e9-6aaf2b503e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1ffe10ba514a79a32462a65e8cc813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/1629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:04<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HadamardEmbedder': {'accuracy': 0.541913632514818, 'precision': 0.7526315789473684, 'recall': 0.12139219015280135, 'f1-score': 0.2090643274853801, 'auc': 0.5408481221034277}, 'AverageEmbedder': {'accuracy': 0.7159187129551228, 'precision': 0.6975837879968823, 'recall': 0.7597623089983022, 'f1-score': 0.7273466070702965, 'auc': 0.7160298031477998}, 'WeightedL1Embedder': {'accuracy': 0.5055038103302286, 'precision': 0.6190476190476191, 'recall': 0.022071307300509338, 'f1-score': 0.042622950819672135, 'auc': 0.504278896893498}, 'WeightedL2Embedder': {'accuracy': 0.506350550381033, 'precision': 0.625, 'recall': 0.025466893039049237, 'f1-score': 0.048939641109298535, 'auc': 0.5051320951681733}}\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = train_and_evaluate_node2vec(df50)\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e617d1dd-5f17-4dd1-8d14-5bd92f99a105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7f961022e5b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb96ddff-8792-4024-b287-2377d78667fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges, test_edges, train_labels, y = train_test_split(list(range(len(G_bu.edges))), \n",
    "                                                             list(nx.get_edge_attributes(G_bu, \"label\").values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc8cba97-6f77-4f04-9865-5054bf52f0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8854,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13085652-cc1f-457e-ab48-bf963b9eb8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2952,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "feb457b9-c205-46f0-886b-3710e497fa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2a9cd27b-c225-4009-bb8e-bfe4162d02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_book(fraudTrain, fraudrate, n, prev_results=None):\n",
    "    if prev_results is None:\n",
    "        df_results = pd.DataFrame(columns=[\n",
    "            'model', 'time', 'acc', 'pre', 'rec', 'f1', 'auc', 'graph_based', \n",
    "            'method', 'throw_rate', 'train_size', 'train_cols', 'train_frate', \n",
    "            'test_size', 'test_frate', 'hyper_params'\n",
    "        ])\n",
    "    else:\n",
    "        df_results = prev_results\n",
    "    \n",
    "    dfrate = throw(fraudTrain, fraudrate)\n",
    "    df_tr, df_tst = sklearn.model_selection.train_test_split(dfrate)\n",
    "        \n",
    "    dfn = fraudTrain[::n]\n",
    "    dfnn = dfn[~dfn.index.isin(df_tr.index)]\n",
    "    dfnn = dfnn.reset_index(drop=True)\n",
    "    df_trn, df_tstn = sklearn.model_selection.train_test_split(dfnn)\n",
    "   \n",
    "    df2, mask = concat(df_tr, df_tstn)\n",
    "    df2['index'] = df2.index\n",
    "    df = df2.reset_index()\n",
    "\n",
    "    G_df = build_graph_tripartite(df, nx.Graph())\n",
    "\n",
    "    train_edges, test_edges, train_labels, y = train_test_split(list(range(len(G_df.edges))), \n",
    "                                                                 list(nx.get_edge_attributes(G_df, \"label\").values()), \n",
    "                                                                 test_size=0.20, \n",
    "                                                                 random_state=42)\n",
    "\n",
    "    edgs = list(G_df.edges)\n",
    "    train_graph = G_df.edge_subgraph([edgs[x] for x in train_edges]).copy()\n",
    "    train_graph.add_nodes_from(list(set(G_df.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "    node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "    model_train = node2vec_train.fit(window=10)\n",
    "\n",
    "    \n",
    "    classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for cl in classes:\n",
    "        embeddings_train = cl(keyed_vectors=model_train.wv)\n",
    "\n",
    "        train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "        test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "        rf.fit(train_embeddings, train_labels)\n",
    "    \n",
    "        yhat = rf.predict(test_embeddings)\n",
    "        acc = metrics.accuracy_score(y, yhat)\n",
    "        pre = metrics.precision_score(y, yhat)\n",
    "        rec = metrics.recall_score(y, yhat)\n",
    "        f1 = metrics.f1_score(y, yhat)\n",
    "        auc = metrics.roc_auc_score(y, yhat)\n",
    "\n",
    "        c1 = cl.__name__\n",
    "        result = {\n",
    "            'model': 'bipartite',\n",
    "            'time': None,\n",
    "            'acc': acc,\n",
    "            'pre': pre,\n",
    "            'rec': rec,\n",
    "            'f1': f1,\n",
    "            'auc': auc,\n",
    "            'graph_based': True,\n",
    "            'method': 'Proposed',\n",
    "            'throw_rate': df.is_fraud.mean(),\n",
    "            'train_size': len(train_labels),\n",
    "            'train_cols': 'amt',\n",
    "            'train_frate': np.array(train_labels).mean(),\n",
    "            'test_size': len(y),\n",
    "            'test_frate': np.array(y).mean(),\n",
    "            'hyper_params': None,\n",
    "            'theta': None,\n",
    "            'gamma': None\n",
    "        }\n",
    "        \n",
    "        evaluation_results[c1] = result\n",
    "    \n",
    "    df_results = df_results.append(evaluation_results, ignore_index=True)\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5eb44df5-b9bd-409d-b0da-07bec644c2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590565dea7d4426bb57a8ee351ff1ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/36624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [01:33<00:00,  9.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time</th>\n",
       "      <th>acc</th>\n",
       "      <th>pre</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>graph_based</th>\n",
       "      <th>method</th>\n",
       "      <th>throw_rate</th>\n",
       "      <th>train_size</th>\n",
       "      <th>train_cols</th>\n",
       "      <th>train_frate</th>\n",
       "      <th>test_size</th>\n",
       "      <th>test_frate</th>\n",
       "      <th>hyper_params</th>\n",
       "      <th>HadamardEmbedder</th>\n",
       "      <th>AverageEmbedder</th>\n",
       "      <th>WeightedL1Embedder</th>\n",
       "      <th>WeightedL2Embedder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model time  acc  pre  rec   f1  auc graph_based method throw_rate  \\\n",
       "0   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN    NaN        NaN   \n",
       "\n",
       "  train_size train_cols train_frate test_size test_frate hyper_params  \\\n",
       "0        NaN        NaN         NaN       NaN        NaN          NaN   \n",
       "\n",
       "                                    HadamardEmbedder  \\\n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....   \n",
       "\n",
       "                                     AverageEmbedder  \\\n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....   \n",
       "\n",
       "                                  WeightedL1Embedder  \\\n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....   \n",
       "\n",
       "                                  WeightedL2Embedder  \n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_book(fraudTrain, 0.5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "20d5c957-300a-4440-9fb3-72c3e675c892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6f1b8dc39c4975a7a9b764a578fe06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/38826 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [01:38<00:00,  9.86s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time</th>\n",
       "      <th>acc</th>\n",
       "      <th>pre</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>graph_based</th>\n",
       "      <th>method</th>\n",
       "      <th>throw_rate</th>\n",
       "      <th>train_size</th>\n",
       "      <th>train_cols</th>\n",
       "      <th>train_frate</th>\n",
       "      <th>test_size</th>\n",
       "      <th>test_frate</th>\n",
       "      <th>hyper_params</th>\n",
       "      <th>HadamardEmbedder</th>\n",
       "      <th>AverageEmbedder</th>\n",
       "      <th>WeightedL1Embedder</th>\n",
       "      <th>WeightedL2Embedder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model time  acc  pre  rec   f1  auc graph_based method throw_rate  \\\n",
       "0   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN    NaN        NaN   \n",
       "\n",
       "  train_size train_cols train_frate test_size test_frate hyper_params  \\\n",
       "0        NaN        NaN         NaN       NaN        NaN          NaN   \n",
       "\n",
       "                                    HadamardEmbedder  \\\n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....   \n",
       "\n",
       "                                     AverageEmbedder  \\\n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....   \n",
       "\n",
       "                                  WeightedL1Embedder  \\\n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....   \n",
       "\n",
       "                                  WeightedL2Embedder  \n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_book(fraudTrain, 0.4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d34f6170-fc55-4248-8750-76ef5b105788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6028be737a4f60a7d9a4f222c21ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/42479 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [01:54<00:00, 11.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>time</th>\n",
       "      <th>acc</th>\n",
       "      <th>pre</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>graph_based</th>\n",
       "      <th>method</th>\n",
       "      <th>throw_rate</th>\n",
       "      <th>train_size</th>\n",
       "      <th>train_cols</th>\n",
       "      <th>train_frate</th>\n",
       "      <th>test_size</th>\n",
       "      <th>test_frate</th>\n",
       "      <th>hyper_params</th>\n",
       "      <th>HadamardEmbedder</th>\n",
       "      <th>AverageEmbedder</th>\n",
       "      <th>WeightedL1Embedder</th>\n",
       "      <th>WeightedL2Embedder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "      <td>{'model': 'bipartite', 'time': None, 'acc': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model time  acc  pre  rec   f1  auc graph_based method throw_rate  \\\n",
       "0   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN    NaN        NaN   \n",
       "\n",
       "  train_size train_cols train_frate test_size test_frate hyper_params  \\\n",
       "0        NaN        NaN         NaN       NaN        NaN          NaN   \n",
       "\n",
       "                                    HadamardEmbedder  \\\n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....   \n",
       "\n",
       "                                     AverageEmbedder  \\\n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....   \n",
       "\n",
       "                                  WeightedL1Embedder  \\\n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....   \n",
       "\n",
       "                                  WeightedL2Embedder  \n",
       "0  {'model': 'bipartite', 'time': None, 'acc': 0....  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_book(fraudTrain, 0.3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a10263-52a1-47b6-a221-870cd2e8a554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a2837a01274cbb93895a65f5c783a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/49801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [02:24<00:00, 14.42s/it]\n"
     ]
    }
   ],
   "source": [
    "try_book(fraudTrain, 0.2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa13b96b-7ba3-4e67-b1aa-2e8d7aac5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_book(fraudTrain, 0.1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca18d3-d179-433a-b5a1-364c0217c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_book(fraudTrain, 0.09, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ba46e-b609-4484-9fb4-1cdc8553e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_book(fraudTrain, 0.08, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5441cf-b8f7-47e9-9242-3715c11f0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_book(fraudTrain, 0.07, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc8e36e-a414-48c4-b1aa-01aed11817fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_book(fraudTrain, 0.06, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf746d-9d44-4563-8bf8-904fbc6c5d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_book(fraudTrain, 0.05, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72494f6-06fd-4472-9e71-29b244d1fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrate = throw(fraudTrain, 0.5)\n",
    "df_tr, df_tst = sklearn.model_selection.train_test_split(dfrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e1df91-e65c-499a-bfc5-a994821638c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = fraudTrain[::10]\n",
    "dfnn = dfn[~dfn.index.isin(df_tr.index)]\n",
    "dfnn = dfnn.reset_index(drop=True)\n",
    "df_trn, df_tstn = sklearn.model_selection.train_test_split(dfnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec9c462-7b42-4486-9b98-e37c869efc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2, mask = concat(df_tr, df_tstn)\n",
    "df2['index'] = df2.index\n",
    "df = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "309c60f0-d213-4d3f-a40f-53225e16b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_df = build_graph_tripartite(df, nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "958634b7-9080-4e15-abe4-f7f9dfde3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges, test_edges, train_labels, y = train_test_split(list(range(len(G_df.edges))), \n",
    "                                                                 list(nx.get_edge_attributes(G_df, \"label\").values()), \n",
    "                                                                 test_size=0.20, \n",
    "                                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c452fef-6c74-4eb3-829a-5d628827029f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db3759633c042cf864790e12a10df5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/36623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [01:31<00:00,  9.16s/it]\n"
     ]
    }
   ],
   "source": [
    "edgs = list(G_df.edges)\n",
    "train_graph = G_df.edge_subgraph([edgs[x] for x in train_edges]).copy()\n",
    "train_graph.add_nodes_from(list(set(G_df.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13136679-939c-4b2c-a1de-4f47f2748503",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "evaluation_results = {}\n",
    "\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv)\n",
    "\n",
    "    train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "    test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "    rf.fit(train_embeddings, train_labels)\n",
    "\n",
    "    yhat = rf.predict(test_embeddings)\n",
    "    acc = metrics.accuracy_score(y, yhat)\n",
    "    pre = metrics.precision_score(y, yhat)\n",
    "    rec = metrics.recall_score(y, yhat)\n",
    "    f1 = metrics.f1_score(y, yhat)\n",
    "    auc = metrics.roc_auc_score(y, yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5eac894-83d9-45f3-a615-b250f115f082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d0592-570e-4d4c-8cb6-5c644859bbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e76dd-c9d0-45c9-8ad8-f32df6d2d018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93179da4-c6ca-4adb-9045-771d80710bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrate = throw(fraudTrain, fraudrate)\n",
    "    df_tr, df_tst = sklearn.model_selection.train_test_split(dfrate)\n",
    "        \n",
    "    dfn = fraudTrain[::n]\n",
    "    dfnn = dfn[~dfn.index.isin(df_tr.index)]\n",
    "    dfnn = dfnn.reset_index(drop=True)\n",
    "    df_trn, df_tstn = sklearn.model_selection.train_test_split(dfnn)\n",
    "   \n",
    "    df2, mask = concat(df_tr, df_tstn)\n",
    "    df2['index'] = df2.index\n",
    "    df = df2.reset_index()\n",
    "\n",
    "    G_df = build_graph_tripartite(df, nx.Graph())\n",
    "\n",
    "    train_edges, test_edges, train_labels, y = train_test_split(list(range(len(G_df.edges))), \n",
    "                                                                 list(nx.get_edge_attributes(G_df, \"label\").values()), \n",
    "                                                                 test_size=0.20, \n",
    "                                                                 random_state=42)\n",
    "\n",
    "    edgs = list(G_df.edges)\n",
    "    train_graph = G_df.edge_subgraph([edgs[x] for x in train_edges]).copy()\n",
    "    train_graph.add_nodes_from(list(set(G_df.nodes) - set(train_graph.nodes)))\n",
    "\n",
    "    node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "    model_train = node2vec_train.fit(window=10)\n",
    "\n",
    "    \n",
    "    classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for cl in classes:\n",
    "        embeddings_train = cl(keyed_vectors=model_train.wv)\n",
    "\n",
    "        train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "        test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "        rf.fit(train_embeddings, train_labels)\n",
    "    \n",
    "        yhat = rf.predict(test_embeddings)\n",
    "        acc = metrics.accuracy_score(y, yhat)\n",
    "        pre = metrics.precision_score(y, yhat)\n",
    "        rec = metrics.recall_score(y, yhat)\n",
    "        f1 = metrics.f1_score(y, yhat)\n",
    "        auc = metrics.roc_auc_score(y, yhat)\n",
    "\n",
    "        c1 = cl.__name__\n",
    "        result = {\n",
    "            'model': 'bipartite',\n",
    "            'time': None,\n",
    "            'acc': acc,\n",
    "            'pre': pre,\n",
    "            'rec': rec,\n",
    "            'f1': f1,\n",
    "            'auc': auc,\n",
    "            'graph_based': True,\n",
    "            'method': 'Proposed',\n",
    "            'throw_rate': df.is_fraud.mean(),\n",
    "            'train_size': len(train_labels),\n",
    "            'train_cols': 'amt',\n",
    "            'train_frate': np.array(train_labels).mean(),\n",
    "            'test_size': len(y),\n",
    "            'test_frate': np.array(y).mean(),\n",
    "            'hyper_params': None,\n",
    "            'theta': None,\n",
    "            'gamma': None\n",
    "        }\n",
    "        \n",
    "        evaluation_results[c1] = result\n",
    "    \n",
    "    df_results = df_results.append(evaluation_results, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
