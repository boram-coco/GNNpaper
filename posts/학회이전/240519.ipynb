{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c8593b37-a6e6-4ccb-b9b2-349f55cb2b69",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"[FRAUD] 책_코드\"\n",
    "author: \"김보람\"\n",
    "date: \"05/18/2024\"\n",
    "categories:\n",
    "  - graph\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eedf6e-cd2a-40f0-aac9-e8899d5b1acc",
   "metadata": {},
   "source": [
    "# FAURD코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8812aa9-c507-4520-9dfc-38a88301f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "# sklearn\n",
    "from sklearn import model_selection # split함수이용\n",
    "from sklearn import ensemble # RF,GBM\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# gnn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472937e-ac8d-45ab-8d26-454bbbf76c3d",
   "metadata": {},
   "source": [
    "`-` 이분그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44f78797-91db-4943-880f-625f41ff87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_bipartite(df_input, graph_type=nx.Graph()):\n",
    "    df=df_input.copy()\n",
    "    mapping={x:node_id for node_id, x in enumerate(set(df[\"cc_num\"].values.tolist()+\\\n",
    "                                                      df[\"merchant\"].values.tolist()))}\n",
    "    \n",
    "    df[\"from\"]=df[\"cc_num\"].apply(lambda x:mapping[x])  #엣지의 출발점\n",
    "    df[\"to\"]=df[\"merchant\"].apply(lambda x:mapping[x])  #엣지의 도착점\n",
    "    \n",
    "    df = df[['from', 'to', \"amt\", \"is_fraud\"]].groupby(['from','to']).agg({\"is_fraud\":\"sum\",\"amt\":\"sum\"}).reset_index()\n",
    "    df[\"is_fraud\"]=df[\"is_fraud\"].apply(lambda x:1 if x>0 else 0)\n",
    "    \n",
    "    G=nx.from_edgelist(df[[\"from\",\"to\"]].values, create_using=graph_type)\n",
    "    \n",
    "    nx.set_edge_attributes(G, {(int(x[\"from\"]),int(x[\"to\"])):x[\"is_fraud\"] for idx, x in df[[\"from\",\"to\",\"is_fraud\"]].iterrows()}, \"label\")  #엣지 속성 설정,각 속성의 사기 여부부 \n",
    "    \n",
    "    nx.set_edge_attributes(G,{(int(x[\"from\"]),int(x[\"to\"])):x[\"amt\"] for idx,x in df[[\"from\",\"to\",\"amt\"]].iterrows()}, \"weight\") # 엣지 속성 설정, 각 엣지의 거래 금액\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5f718-5b3e-4c30-8d67-f30a737143bb",
   "metadata": {},
   "source": [
    "`-` 삼분그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de4f50b6-213c-4b04-b3bd-4ff0a8221ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_tripartite(df_input, graph_type=nx.Graph()):\n",
    "    df=df_input.copy()\n",
    "    mapping={x:node_id for node_id, x in enumerate(set(df.index.values.tolist() + \n",
    "                                                       df[\"cc_num\"].values.tolist() +\n",
    "                                                       df[\"merchant\"].values.tolist()))}\n",
    "    df[\"in_node\"]= df[\"cc_num\"].apply(lambda x: mapping[x])\n",
    "    df[\"out_node\"]=df[\"merchant\"].apply(lambda x:mapping[x])\n",
    "    \n",
    "        \n",
    "    G=nx.from_edgelist([(x[\"in_node\"], mapping[idx]) for idx, x in df.iterrows()] +\\\n",
    "                        [(x[\"out_node\"], mapping[idx]) for idx, x in df.iterrows()], create_using=graph_type)\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")\n",
    "     \n",
    "    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"is_fraud\"] for idx, x in df.iterrows()}, \"label\")\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"in_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n",
    "    \n",
    "    nx.set_edge_attributes(G,{(x[\"out_node\"], mapping[idx]):x[\"amt\"] for idx, x in df.iterrows()}, \"weight\")\n",
    "    \n",
    "    \n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027823d-ca18-439f-9bea-54460f7d7e70",
   "metadata": {},
   "source": [
    "- 판매자, 고객, 거래에 노드 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56689a45-270d-44d0-8b08-5bd49fda90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = pd.read_csv('~/Dropbox/Data/df_train1.csv')\n",
    "df_train2 = pd.read_csv('~/Dropbox/Data/df_train2.csv')\n",
    "df_train3 = pd.read_csv('~/Dropbox/Data/df_train3.csv')\n",
    "df_train4 = pd.read_csv('~/Dropbox/Data/df_train4.csv')\n",
    "df_train5 = pd.read_csv('~/Dropbox/Data/df_train5.csv')\n",
    "df_train6 = pd.read_csv('~/Dropbox/Data/df_train6.csv')\n",
    "df_train7 = pd.read_csv('~/Dropbox/Data/df_train7.csv')\n",
    "df_train8 = pd.read_csv('~/Dropbox/Data/df_train8.csv')\n",
    "df_test = pd.read_csv('~/Dropbox/Data/df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b518cc2-44cb-490e-8a7d-24bc9aa34308",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df1 = pd.concat([df_train1, df_test])\n",
    "_df2 = pd.concat([df_train2, df_test])\n",
    "_df3 = pd.concat([df_train3, df_test])\n",
    "_df4 = pd.concat([df_train4, df_test])\n",
    "_df5 = pd.concat([df_train5, df_test])\n",
    "_df6 = pd.concat([df_train6, df_test])\n",
    "_df7 = pd.concat([df_train7, df_test])\n",
    "_df8 = pd.concat([df_train8, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a803d9-dc63-4c2f-96e9-7b78b57d344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_bi_8 = build_graph_bipartite(df_train8, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_bi_7 = build_graph_bipartite(df_train7, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_bi_6 = build_graph_bipartite(df_train6, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_bi_5 = build_graph_bipartite(df_train5, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_bi_4 = build_graph_bipartite(df_train4, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_bi_3 = build_graph_bipartite(df_train3, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_bi_2 = build_graph_bipartite(df_train2, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_bi_1 = build_graph_bipartite(df_train1, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_bi_test = build_graph_bipartite(df_test, nx.Graph(name=\"Bipartite Undirect\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52160026-727f-4e6a-b6e7-8fea5b15213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_8 = build_graph_bipartite(_df8, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_7 = build_graph_bipartite(_df7, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_6 = build_graph_bipartite(_df6, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_5 = build_graph_bipartite(_df5, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_4 = build_graph_bipartite(_df4, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_3 = build_graph_bipartite(_df3, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_2 = build_graph_bipartite(_df2, nx.Graph(name=\"Bipartite Undirect\"))\n",
    "G_1 = build_graph_bipartite(_df1, nx.Graph(name=\"Bipartite Undirect\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3a43a7b-30ff-4de4-98aa-bef38365830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_edges, test_edges, train_labels, test_labels = train_test_split(list(range(len(G_8.edges))), \n",
    "                                                                      list(nx.get_edge_attributes(G_8, \"label\").values()), \n",
    "                                                                      test_size=0.973961397229567, \n",
    "                                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ecbfefb-fd75-4b34-b45e-4e6f70cdcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs = list(G_8.edges)\n",
    "train_graph = G_8.edge_subgraph([edgs[x] for x in train_edges]).copy()\n",
    "train_graph.add_nodes_from(list(set(G_8.nodes) - set(train_graph.nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770085b1-fbfc-4511-813c-5a25a7d54355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6002, 1636)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph.number_of_edges(), train_graph.number_of_nodes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd2289-1468-456b-a00f-fe7f851fb9bd",
   "metadata": {},
   "source": [
    "- 데이터 8:2 비율로 학습 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab4daf40-17bb-4ddc-a0ae-ddf7b5449d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5344999519a4560a48349346907e340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/1636 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:03<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder\n",
    "\n",
    "node2vec_train = Node2Vec(train_graph, weight_key='weight')\n",
    "model_train = node2vec_train.fit(window=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384e4bb-9dc7-4ef4-a3f0-fc0df1878335",
   "metadata": {},
   "source": [
    "- Node2Vec 알고리즘 사용해 특징 공간 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6182fb3a-d48e-4853-86df-85da6b2173e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'node2vec.edges.HadamardEmbedder'>\n",
      "Precision: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Accuracy: 0.9743555484296225\n",
      "auc: 0.5\n",
      "<class 'node2vec.edges.AverageEmbedder'>\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Accuracy: 0.9743110113480484\n",
      "auc: 0.49997714536462284\n",
      "<class 'node2vec.edges.WeightedL1Embedder'>\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.0001736714136853074\n",
      "F1-Score: 0.0003471619510501649\n",
      "Accuracy: 0.9743510947214651\n",
      "auc: 0.5000822647797671\n",
      "<class 'node2vec.edges.WeightedL2Embedder'>\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.0001736714136853074\n",
      "F1-Score: 0.0003471619510501649\n",
      "Accuracy: 0.9743510947214651\n",
      "auc: 0.5000822647797671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "classes = [HadamardEmbedder, AverageEmbedder, WeightedL1Embedder, WeightedL2Embedder]\n",
    "\n",
    "for cl in classes:\n",
    "    embeddings_train = cl(keyed_vectors=model_train.wv)\n",
    "\n",
    "    train_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in train_edges]\n",
    "    test_embeddings = [embeddings_train[str(edgs[x][0]), str(edgs[x][1])] for x in test_edges]\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "    rf.fit(train_embeddings, train_labels)\n",
    "\n",
    "    y_pred = rf.predict(test_embeddings)\n",
    "    print(cl)\n",
    "    print('Precision:', metrics.precision_score(test_labels, y_pred))\n",
    "    print('Recall:', metrics.recall_score(test_labels, y_pred))\n",
    "    print('F1-Score:', metrics.f1_score(test_labels, y_pred))\n",
    "    print('Accuracy:', metrics.accuracy_score(test_labels, y_pred))\n",
    "    print('auc:', metrics.roc_auc_score(test_labels, y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2cf10-49b8-40c4-8f97-e53e2b1961f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
