{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ead89876-ba70-480c-9ed6-8c8863b7c978",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"불균형 데이터 proposed(확률값 넣어서 auc값 해보기)\"\n",
    "author: \"김보람\"\n",
    "date: \"02/04/2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bfdec3-5b07-45b5-9b38-2e8813117310",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb91738-6398-4ffc-bbec-fc48fcc8f249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/torch_geometric/typing.py:18: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/libpyg.so: undefined symbol: _ZN2at4_ops12split_Tensor4callERKNS_6TensorEN3c106SymIntEl\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/torch_geometric/typing.py:31: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/torch_scatter/_scatter_cuda.so: undefined symbol: _ZNK3c107SymBool10guard_boolEPKcl\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/torch_geometric/typing.py:42: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/torch_sparse/_diag_cuda.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowIlEET_S2_S2_b\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "# sklearn\n",
    "from sklearn import model_selection # split함수이용\n",
    "from sklearn import ensemble # RF,GBM\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# gnn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2774d96b-b24a-492b-a587-2815ff6e3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def throw(df, fraud_rate):  # 사기 거래 비율에 맞춰 버려지는 함수!\n",
    "    df1 = df[df['is_fraud'] == 1].copy()\n",
    "    df0 = df[df['is_fraud'] == 0].copy()\n",
    "    df0_downsample = (len(df1) * (1-fraud_rate)) / (len(df0) * fraud_rate)\n",
    "    df0_down = df0.sample(frac=df0_downsample, random_state=42)\n",
    "    df_p = pd.concat([df1, df0_down])\n",
    "    return df_p\n",
    "\n",
    "def split_dataframe(data_frame, test_fraud_rate, test_rate=0.3):\n",
    "    n = len(data_frame)\n",
    "\n",
    "    # 사기 거래와 정상 거래를 분리\n",
    "    fraud_data = data_frame[data_frame['is_fraud'] == 1]\n",
    "    normal_data = data_frame[data_frame['is_fraud'] == 0]\n",
    "\n",
    "    # 테스트 데이터 크기 계산\n",
    "    test_samples = int(test_fraud_rate * (n * test_rate))\n",
    "    remaining_test_samples = int(n * test_rate) - test_samples\n",
    "\n",
    "    # 사기 거래 및 정상 거래에서 무작위로 테스트 데이터 추출\n",
    "    test_fraud_data = fraud_data.sample(n=test_samples, replace=False)\n",
    "    test_normal_data = normal_data.sample(n=remaining_test_samples, replace=False)\n",
    "\n",
    "    # 테스트 데이터 합치기\n",
    "    test_data = pd.concat([test_normal_data, test_fraud_data])\n",
    "\n",
    "    # 훈련 데이터 생성\n",
    "    train_data = data_frame[~data_frame.index.isin(test_data.index)]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "def concat(df_tr, df_tst):   \n",
    "    df = pd.concat([df_tr, df_tst])\n",
    "    train_mask = np.concatenate((np.full(len(df_tr), True), np.full(len(df_tst), False)))    # index꼬이는거 방지하기 위해서? ★ (이거,, 훔,,?(\n",
    "    test_mask =  np.concatenate((np.full(len(df_tr), False), np.full(len(df_tst), True))) \n",
    "    mask = (train_mask, test_mask)\n",
    "    return df, mask\n",
    "\n",
    "def evaluation(y, yhat):\n",
    "    metrics = [sklearn.metrics.accuracy_score,\n",
    "               sklearn.metrics.precision_score,\n",
    "               sklearn.metrics.recall_score,\n",
    "               sklearn.metrics.f1_score,\n",
    "               sklearn.metrics.roc_auc_score]\n",
    "    return pd.DataFrame({m.__name__:[m(y,yhat).round(6)] for m in metrics})\n",
    "\n",
    "def compute_time_difference(group):\n",
    "    n = len(group)\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            time_difference = abs((group.iloc[i].trans_date_trans_time - group.iloc[j].trans_date_trans_time).total_seconds())\n",
    "            result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n",
    "    return result\n",
    "\n",
    "def edge_index(df, unique_col, theta, gamma):\n",
    "    groups = df.groupby(unique_col)\n",
    "    edge_index = np.array([item for sublist in (compute_time_difference(group) for _, group in groups) for item in sublist])\n",
    "    edge_index = edge_index.astype(np.float64)\n",
    "    # filename = f\"edge_index{str(unique_col).replace(' ', '').replace('_', '')}.npy\"  # 저장\n",
    "    # np.save(filename, edge_index)\n",
    "    edge_index[:,2] = (np.exp(-edge_index[:,2]/(theta)) != 1)*(np.exp(-edge_index[:,2]/(theta))).tolist()\n",
    "    edge_index = torch.tensor([(int(row[0]), int(row[1])) for row in edge_index if row[2] > gamma], dtype=torch.long).t()\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "\n",
    "def gcn_data(df):\n",
    "    x = torch.tensor(df['amt'].values, dtype=torch.float).reshape(-1,1)\n",
    "    y = torch.tensor(df['is_fraud'].values,dtype=torch.int64)\n",
    "    data = torch_geometric.data.Data(x=x, edge_index = edge_index, y=y, train_mask = mask[0], test_mask= mask[1])\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7618f574-3107-45b2-9445-c01be0713eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(1, 32)\n",
    "        self.conv2 = GCNConv(32, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_and_evaluate_model(data, model, optimizer, num_epochs=400):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    yyhat = pred[data.test_mask]\n",
    "    \n",
    "    return yyhat\n",
    "\n",
    "# # 모델과 옵티마이저 생성\n",
    "# model = GCN1()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# # 함수 호출\n",
    "# yyhat = train_and_evaluate_model(data, model, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de68f710-9a73-416f-bbd9-3f9b555643a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('fraudTrain.pkl', 'rb') as file:\n",
    "    fraudTrain = pickle.load(file)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb67e43-b7f2-40da-9fc1-33d18b5747df",
   "metadata": {},
   "source": [
    "#  (throw 0.3 /split 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc0c366-9559-4f51-8088-d0a9d3187ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = throw(fraudTrain, 0.3)\n",
    "df_tr, df_tst = split_dataframe(df, 0.05)\n",
    "df2, mask = concat(df_tr, df_tst)\n",
    "df2['index'] = df2.index\n",
    "df3 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674f7355-6270-4bc6-b3bb-04a3f4cd18b7",
   "metadata": {},
   "source": [
    "## 시도1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4deed04-358a-45e8-9937-15167ab7506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edge_index(df3,'cc_num', 8.028000e+04, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc487356-d6df-44d2-afaf-2478f175b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gcn_data(df3)\n",
    "model = GCN1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "yy = (data.y[data.test_mask]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb2b4c10-278b-4ace-ae3e-732de084230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(400):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "yyhat = pred[data.test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "685b51f9-f68b-4f75-a85b-ddff110e99d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4273, -0.0330],\n",
       "        [-0.3912, -1.1277],\n",
       "        [-0.3912, -1.1277],\n",
       "        ...,\n",
       "        [-5.0603, -0.0064],\n",
       "        [-1.6619, -0.2104],\n",
       "        [-3.6349, -0.0267]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb1beae-139f-405c-a3fd-860b1a1a2599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a909640-d8f5-4b8c-b69f-de7c33267a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5d512-efa7-4fb5-8a9e-d0bdde9bc478",
   "metadata": {},
   "source": [
    "- model(data)값이 logsoftmax취해진 값이라 exp취해줘보기..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e7a8302-c8a7-46d5-a29d-3a54b2184caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9675, 0.3238, 0.3238,  ..., 0.9937, 0.8102, 0.9736],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(model(data))[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a612699-c0ca-4d00-af0d-84d17481acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_ = model(data)[:,-1][data.test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "571868f0-1664-4b86-b17d-0ca925d5cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_01 = yhat_ > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9826b0af-f96f-498f-a0bc-71ef3b2bafdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coco/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc = sklearn.metrics.accuracy_score(yy,yhat_01)\n",
    "pre = sklearn.metrics.precision_score(yy,yhat_01)\n",
    "rec = sklearn.metrics.recall_score(yy,yhat_01)\n",
    "f1 = sklearn.metrics.f1_score(yy,yhat_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ba10489-c4fc-451e-afc5-b83fcaa46808",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat__ = yhat_.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a46e265c-d3d5-4862-a2e1-b604b1a9f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = sklearn.metrics.roc_auc_score(yy,yhat__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "256433bf-b417-4ff9-b01c-c12ae8552971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9500499500499501, 0.0, 0.0, 0.0, 0.9889841102932585)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, pre, rec, f1, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c753fea-8acf-4144-b1f3-c8d28ab708a9",
   "metadata": {},
   "source": [
    "---> 그냥 넣었떠니 acc, auc 빼고 다 0나옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ff8fe8f-8929-4d45-84cf-f9b9ab223527",
   "metadata": {},
   "outputs": [],
   "source": [
    "yyhat2 = torch.exp(model(data))[:,-1][data.test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "006b9940-3da3-4682-adb2-a23d1778ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_02 = yyhat2 > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fc458bc-f716-4000-8f26-0510259e7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = sklearn.metrics.accuracy_score(yy,yhat_02)\n",
    "pre = sklearn.metrics.precision_score(yy,yhat_02)\n",
    "rec = sklearn.metrics.recall_score(yy,yhat_02)\n",
    "f1 = sklearn.metrics.f1_score(yy,yhat_02)\n",
    "#auc = sklearn.metrics.roc_auc_score(y,yyhat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6033be9b-48fa-402d-9b73-d805bf89cb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9716949716949717, 0.6477272727272727, 0.95, 0.7702702702702702)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, pre, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a26b95fb-613f-4948-8af7-fb93843ea4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yyhat22 = yyhat2.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6eb8de3f-7e24-4e2c-9682-c74921dd073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = sklearn.metrics.roc_auc_score(yy,yyhat22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10cff396-fe1d-4b64-987e-dfd783dbaeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9889841102932585"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fcbd00-ce7b-417d-9619-0f4551a63786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a031456-c9a8-458b-99fd-27affe1bb9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a6db865-1151-43fc-a33d-f49014880e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y, yhat):\n",
    "    y = pd.Series(np.array(y).reshape(-1))\n",
    "    yhat = pd.Series(np.array(yhat).reshape(-1))\n",
    "    nan_rate = pd.Series(yhat).isna().mean()\n",
    "    nan_index = pd.Series(yhat).isna()\n",
    "    y = np.array(y)[~nan_index]\n",
    "    yhat_prob = np.array(yhat)[~nan_index]\n",
    "    yhat_01 = yhat_prob > 0.5\n",
    "    acc = sklearn.metrics.accuracy_score(y,yhat_01)\n",
    "    pre = sklearn.metrics.precision_score(y,yhat_01)\n",
    "    rec = sklearn.metrics.recall_score(y,yhat_01)\n",
    "    f1 = sklearn.metrics.f1_score(y,yhat_01)\n",
    "    auc = sklearn.metrics.roc_auc_score(y,yhat_prob)\n",
    "    return {'acc':acc,'pre':pre,'rec':rec,'f1':f1,'auc':auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dba92204-d6b2-437b-b1f4-21f81095af95",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(np\u001b[38;5;241m.\u001b[39marray(yy)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m yhat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(np\u001b[38;5;241m.\u001b[39marray(yyhat)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m nan_rate \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43myyhat_\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      4\u001b[0m nan_index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(yyhat_)\u001b[38;5;241m.\u001b[39misna()\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(yy)[\u001b[38;5;241m~\u001b[39mnan_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/series.py:470\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    468\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/construction.py:616\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# materialize e.g. generators, convert e.g. tuples, abc.ValueView\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# e.g. dask array GH#38645\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/_tensor.py:956\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "y = pd.Series(np.array(yy).reshape(-1))\n",
    "yhat = pd.Series(np.array(yyhat).reshape(-1))\n",
    "nan_rate = pd.Series(yyhat_).isna().mean()\n",
    "nan_index = pd.Series(yyhat_).isna()\n",
    "y = np.array(yy)[~nan_index]\n",
    "yhat_prob = np.array(yyhat_)[~nan_index]\n",
    "yhat_01 = yhat_prob > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bcb426-7080-42bf-a967-e174397cffda",
   "metadata": {},
   "source": [
    "- numpy로 하려고 하니깡 안되네으"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e803b7-74d0-49c9-b9ec-5ed8642ac1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f595fc-af7f-4efb-ba8a-518f63386d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c94091-b844-46d9-ae4c-b81243fc90a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc22c834-f239-4ad5-9c4d-0de486b10c1c",
   "metadata": {},
   "source": [
    "`-` 그냥 기존에 돌렸떤 evaluate 값이랑 같은 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f3123ae-ef29-4144-b08c-cf9beaecca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "yyhat = train_and_evaluate_model(data, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e54815fb-d61f-4d98-84f0-fa7b854212f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdee5eec-c5ae-4dbb-b2be-c946a4ebe94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9696969696969697,\n",
       " 'pre': 0.6299559471365639,\n",
       " 'rec': 0.9533333333333334,\n",
       " 'f1': 0.7586206896551724,\n",
       " 'auc': 0.9619453207150368}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(yy, yyhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260beca7-0a88-4b80-be7e-6d58249b3fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8afe84-15a2-4379-b547-ad53aff5668e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beecd12b-81aa-43af-8564-5a3a2fbb85e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebb344db-dc30-4ce1-a66d-7fa7e2be480e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
