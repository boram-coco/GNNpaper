{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ead89876-ba70-480c-9ed6-8c8863b7c978",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"불균형 데이터 proposed (throw 0.3 /split 0.05, 0.005)\"\n",
    "author: \"김보람\"\n",
    "date: \"01/26/2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549356f3-3bf8-4b4a-86ad-075ec9c7c2fb",
   "metadata": {},
   "source": [
    "\n",
    "# 정리\n",
    "\n",
    "| 구분  | Throw(fraud_rate)   | split(test_fraud_rate)      | theta          | gamma | 비고 |\n",
    "|-------|---------|-----------|---------------|----------|------|\n",
    "| 시도1 | 0.3 | 0.05 | 8.028000e+04 | 0.3  | |\n",
    "| 시도2 | 0.3 | 0.05 | 8.028000e+04 | 0.2  | |\n",
    "| 시도3 | 0.3 | 0.05 | 9.028000e+04 | 0.2  | |\n",
    "| 시도4 | 0.3 | 0.05 | 7.028000e+04 |  0.2 | |\n",
    "| 시도5 | 0.3 | 0.005 | 7.028000e+04 |  0.3 |  |\n",
    "| 시도6 | 0.3 | 0.005 | 8.028000e+04 | 0.2  | |\n",
    "| 시도7 | 0.3 | 0.005 | 9.028000e+04 | 0.2  | |\n",
    "| 시도8 | 0.3 | 0.005 | 7.028000e+04 |  0.2 | |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "888e602e-af08-4c7e-a79e-741c6b38a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = [results1,results2,results3,results4,results5,results6,results7,results8]\n",
    "# pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f6163018-858a-40d6-bc1e-fab776b836b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.970862</td>\n",
       "      <td>0.639821</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.765730</td>\n",
       "      <td>0.962559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.968365</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.959665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970030</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.955804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967865</td>\n",
       "      <td>0.616558</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.745718</td>\n",
       "      <td>0.956244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.969530</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.758893</td>\n",
       "      <td>0.965016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.970196</td>\n",
       "      <td>0.635955</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.759732</td>\n",
       "      <td>0.957471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.970529</td>\n",
       "      <td>0.633987</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.766798</td>\n",
       "      <td>0.970279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.968531</td>\n",
       "      <td>0.618337</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.754226</td>\n",
       "      <td>0.967648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  precision_score  recall_score  f1_score  roc_auc_score\n",
       "1        0.970862         0.639821      0.953333  0.765730       0.962559\n",
       "2        0.968365         0.619565      0.950000  0.750000       0.959665\n",
       "3        0.970030         0.635135      0.940000  0.758065       0.955804\n",
       "4        0.967865         0.616558      0.943333  0.745718       0.956244\n",
       "5        0.969530         0.627451      0.960000  0.758893       0.965016\n",
       "6        0.970196         0.635955      0.943333  0.759732       0.957471\n",
       "7        0.970529         0.633987      0.970000  0.766798       0.970279\n",
       "8        0.968531         0.618337      0.966667  0.754226       0.967648"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bfdec3-5b07-45b5-9b38-2e8813117310",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4eb91738-6398-4ffc-bbec-fc48fcc8f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "# sklearn\n",
    "from sklearn import model_selection # split함수이용\n",
    "from sklearn import ensemble # RF,GBM\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# gnn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2774d96b-b24a-492b-a587-2815ff6e3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def throw(df, fraud_rate):  # 사기 거래 비율에 맞춰 버려지는 함수!\n",
    "        df1 = df[df['is_fraud'] == 1].copy()\n",
    "        df0 = df[df['is_fraud'] == 0].copy()\n",
    "        df0_downsample = (len(df1) * (1-fraud_rate)) / (len(df0) * fraud_rate)\n",
    "        df0_down = df0.sample(frac=df0_downsample, random_state=42)\n",
    "        df_p = pd.concat([df1, df0_down])\n",
    "        return df_p\n",
    "    \n",
    "    def split_dataframe(data_frame, test_fraud_rate, test_rate=0.3):\n",
    "        n = len(data_frame)\n",
    "    \n",
    "        # 사기 거래와 정상 거래를 분리\n",
    "        fraud_data = data_frame[data_frame['is_fraud'] == 1]\n",
    "        normal_data = data_frame[data_frame['is_fraud'] == 0]\n",
    "\n",
    "        # 테스트 데이터 크기 계산\n",
    "        test_samples = int(test_fraud_rate * (n * test_rate))\n",
    "        remaining_test_samples = int(n * test_rate) - test_samples\n",
    "    \n",
    "        # 사기 거래 및 정상 거래에서 무작위로 테스트 데이터 추출\n",
    "        test_fraud_data = fraud_data.sample(n=test_samples, replace=False)\n",
    "        test_normal_data = normal_data.sample(n=remaining_test_samples, replace=False)\n",
    "\n",
    "        # 테스트 데이터 합치기\n",
    "        test_data = pd.concat([test_normal_data, test_fraud_data])\n",
    "\n",
    "        # 훈련 데이터 생성\n",
    "        train_data = data_frame[~data_frame.index.isin(test_data.index)]\n",
    "\n",
    "        return train_data, test_data\n",
    "    \n",
    "    def concat(df_tr, df_tst):   \n",
    "        df = pd.concat([df_tr, df_tst])\n",
    "        train_mask = np.concatenate((np.full(len(df_tr), True), np.full(len(df_tst), False)))    # index꼬이는거 방지하기 위해서? ★ (이거,, 훔,,?(\n",
    "        test_mask =  np.concatenate((np.full(len(df_tr), False), np.full(len(df_tst), True))) \n",
    "        mask = (train_mask, test_mask)\n",
    "        return df, mask\n",
    "        \n",
    "    def evaluation(y, yhat):\n",
    "        metrics = [sklearn.metrics.accuracy_score,\n",
    "                   sklearn.metrics.precision_score,\n",
    "                   sklearn.metrics.recall_score,\n",
    "                   sklearn.metrics.f1_score,\n",
    "                   sklearn.metrics.roc_auc_score]\n",
    "        return pd.DataFrame({m.__name__:[m(y,yhat).round(6)] for m in metrics})\n",
    "        \n",
    "    def compute_time_difference(group):\n",
    "        n = len(group)\n",
    "        result = []\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                time_difference = abs((group.iloc[i].trans_date_trans_time - group.iloc[j].trans_date_trans_time).total_seconds())\n",
    "                result.append([group.iloc[i].name, group.iloc[j].name, time_difference])\n",
    "        return result\n",
    "\n",
    "    def edge_index(df, unique_col, theta, gamma):\n",
    "        groups = df.groupby(unique_col)\n",
    "        edge_index = np.array([item for sublist in (compute_time_difference(group) for _, group in groups) for item in sublist])\n",
    "        edge_index = edge_index.astype(np.float64)\n",
    "        # filename = f\"edge_index{str(unique_col).replace(' ', '').replace('_', '')}.npy\"  # 저장\n",
    "        # np.save(filename, edge_index)\n",
    "        edge_index[:,2] = (np.exp(-edge_index[:,2]/(theta)) != 1)*(np.exp(-edge_index[:,2]/(theta))).tolist()\n",
    "        edge_index = torch.tensor([(int(row[0]), int(row[1])) for row in edge_index if row[2] > gamma], dtype=torch.long).t()\n",
    "        return edge_index\n",
    "\n",
    "\n",
    "    \n",
    "    def gcn_data(df):\n",
    "        x = torch.tensor(df['amt'].values, dtype=torch.float).reshape(-1,1)\n",
    "        y = torch.tensor(df['is_fraud'].values,dtype=torch.int64)\n",
    "        data = torch_geometric.data.Data(x=x, edge_index = edge_index, y=y, train_mask = mask[0], test_mask= mask[1])\n",
    "        return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7618f574-3107-45b2-9445-c01be0713eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(1, 32)\n",
    "        self.conv2 = GCNConv(32, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_and_evaluate_model(data, model, optimizer, num_epochs=400):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    yyhat = pred[data.test_mask]\n",
    "    \n",
    "    return yyhat\n",
    "\n",
    "# # 모델과 옵티마이저 생성\n",
    "# model = GCN1()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# # 함수 호출\n",
    "# yyhat = train_and_evaluate_model(data, model, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42fa6325-c247-4938-8783-79e4191ede85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudTrain = pd.read_csv(\"~/Desktop/fraudTrain.csv\").iloc[:,1:]\n",
    "fraudTrain = fraudTrain.assign(trans_date_trans_time= list(map(lambda x: pd.to_datetime(x), fraudTrain.trans_date_trans_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb67e43-b7f2-40da-9fc1-33d18b5747df",
   "metadata": {},
   "source": [
    "#  (throw 0.3 /split 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "abc0c366-9559-4f51-8088-d0a9d3187ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = throw(fraudTrain, 0.3)\n",
    "df_tr, df_tst = split_dataframe(df, 0.05)\n",
    "df2, mask = concat(df_tr, df_tst)\n",
    "df2['index'] = df2.index\n",
    "df3 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e45838a4-f230-4857-89d0-603ebd2a26b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.is_fraud.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aecfab10-0ba7-480b-9a1b-a6b7885ecc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04995004995004995"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tst.is_fraud.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674f7355-6270-4bc6-b3bb-04a3f4cd18b7",
   "metadata": {},
   "source": [
    "## 시도1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bdf7c775-bec9-4885-a054-0ecaf4afa1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edge_index(df3,'cc_num', 8.028000e+04, 0.3)\n",
    "data = gcn_data(df3)\n",
    "model = GCN1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "yy = (data.y[data.test_mask]).numpy()\n",
    "yyhat = train_and_evaluate_model(data, model, optimizer)\n",
    "results1=evaluation(yy,yyhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb344db-dc30-4ce1-a66d-7fa7e2be480e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64deab26-5846-414f-afee-309650f0d6fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 시도2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "238abeba-f57e-40e8-87e6-86bb35eda225",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edge_index(df3,'cc_num', 8.028000e+04, 0.2)\n",
    "data = gcn_data(df3)\n",
    "model = GCN1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "yy = (data.y[data.test_mask]).numpy()\n",
    "yyhat = train_and_evaluate_model(data, model, optimizer)\n",
    "results2=evaluation(yy,yyhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ce3192-87f5-47e0-a3b0-a3f58e0d8b82",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f566260-e442-442f-a988-351a7aed90b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 시도3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44f64737-eb18-44bd-bb93-2573ba7d9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edge_index2(df3,'cc_num', 9.028000e+04, 0.2) \n",
    "data = gcn_data(df3)\n",
    "model = GCN1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "yy = (data.y[data.test_mask]).numpy()\n",
    "yyhat = train_and_evaluate_model(data, model, optimizer)\n",
    "results3=evaluation(yy,yyhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c88d2-d700-4992-9cba-3b87e65a683e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41677d78-c76b-4948-9f15-dac3bf679132",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 시도4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38f39ae9-290e-4fd5-80d6-42a744f8c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edge_index2(df3,'cc_num', 7.028000e+04, 0.2) \n",
    "data = gcn_data(df3)\n",
    "model = GCN1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "yy = (data.y[data.test_mask]).numpy()\n",
    "yyhat = train_and_evaluate_model(data, model, optimizer)\n",
    "results4=evaluation(yy,yyhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b50bde-a3c6-45b7-af0d-f983eecf8056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "534dafea-5808-478c-8643-0b823902da97",
   "metadata": {},
   "source": [
    "#  (throw 0.3 /split 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "004c2185-e74c-4d43-82fe-2f88bff95570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = throw(fraudTrain, 0.3)\n",
    "df_tr, df_tst = split_dataframe(df, 0.005)\n",
    "df2, mask = concat(df_tr, df_tst)\n",
    "df2['index'] = df2.index\n",
    "df3 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb9ea658-c77e-4f39-9b48-4541f34f7fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.is_fraud.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2413705f-80f4-4c65-9e50-071358c88e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004995004995004995"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tst.is_fraud.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430bb2f-d12a-4cad-80e9-1abe226ee53d",
   "metadata": {},
   "source": [
    "## 시도5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fdaf1d6a-db2d-4d26-8163-1de0dfe0205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edge_index(df3,'cc_num', 8.028000e+04, 0.3)\n",
    "data = gcn_data(df3)\n",
    "model = GCN1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "yy = (data.y[data.test_mask]).numpy()\n",
    "yyhat = train_and_evaluate_model(data, model, optimizer)\n",
    "results5=evaluation(yy,yyhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa868436-0cdb-48f3-9f17-6b99a4f1ecd4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8dcbd-35ff-4141-bddf-652f0078830f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 시도6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f5acc308-74be-4ccc-972a-a6dae8654930",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edge_index(df3,'cc_num', 8.028000e+04, 0.2)\n",
    "data = gcn_data(df3)\n",
    "model = GCN1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "yy = (data.y[data.test_mask]).numpy()\n",
    "yyhat = train_and_evaluate_model(data, model, optimizer)\n",
    "results6=evaluation(yy,yyhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75eaa61-98b6-4026-a712-e0f5138c1cec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58216384-71cb-4d41-b8ac-6bd1c611b208",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 시도7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5841c230-7cb4-496f-ab26-1517fe6bc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edge_index2(df3,'cc_num', 9.028000e+04, 0.2) \n",
    "data = gcn_data(df3)\n",
    "model = GCN1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "yy = (data.y[data.test_mask]).numpy()\n",
    "yyhat = train_and_evaluate_model(data, model, optimizer)\n",
    "results7=evaluation(yy,yyhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b43bd4-12fa-42f6-b92f-cee1f5184f3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df642b01-e04f-41e0-8a62-fbb9048ff314",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 시도8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "25c57cf7-8ffd-428a-a73b-9cf73a7ab6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edge_index2(df3,'cc_num', 7.028000e+04, 0.2) \n",
    "data = gcn_data(df3)\n",
    "model = GCN1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "yy = (data.y[data.test_mask]).numpy()\n",
    "yyhat = train_and_evaluate_model(data, model, optimizer)\n",
    "results8=evaluation(yy,yyhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1a544-c8fa-4791-908c-ae4fa4732e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
